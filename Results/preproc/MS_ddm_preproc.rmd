---
title: "Data_Analysis_MS_ddm_exp1"
author: "hcp"
date: "2017-12"
output: word_document
---
<style type="text/css">

body{ /* Normal  */
   font-family: Times     
   font-size: 12px;
}
td {  /* Table  */
   font-size: 8px;
}
h1 { /* Header 1 */
 font-size: 28px;
}
h2 { /* Header 2 */
 font-size: 22px;
}
h3 { /* Header 3 */
 font-size: 18px;
 color: DarkBlue;
}
code.r{ /* Code block */
  font-size: 10px;
}
pre { /* Code block */
  font-size: 10px
}
</style>


This script is aimed at making the analysis of the moral self experiment (DDM) reproducible. We analyzezd the data using the traditional ways (d prime/Accuracy and mean of RT)

```{r Initializing, include=FALSE}
source('Initial.r')
curDir  <- getwd()
#curDir  <- dirname(rstudioapi::getSourceEditorContext()$path)   # directory for preprocessing
rootDir <- gsub('.{7}$', '', curDir)
#rawDir <- paste(curDir,'/data/',sep = '')
traDir <- paste(rootDir,'Traditional_Analysis',sep = '')
ddmDir <- paste(rootDir,'HDDM',sep = '')
exgDir <- paste(rootDir,'exGaussian',sep = '')
```


```{r loadingData_MS_ddm_exp1,echo=FALSE,results='hide'}
df.M <- read.csv("MS_matchTask_raw.csv",header = TRUE, sep = ',', stringsAsFactors=FALSE) # data for matching task
df.C <- read.csv("MS_categTask_raw.csv",header = TRUE, sep = ',', stringsAsFactors=FALSE)  # data for categorization task

subTotl <- unique(df.M$Subject)

# make the variables in a specified order
df.M$Morality <- factor(df.M$Morality, levels = c("Good","Bad"))    
df.M$Identity <- factor(df.M$Identity, levels = c("Self","Other"))  
df.M$Match    <- factor(df.M$Match,    levels = c("match","nonmatch"))

# make the variables in a specified order
df.C$Morality <- factor(df.C$Morality, levels=c("Good","Bad"))    
df.C$Identity <- factor(df.C$Identity, levels=c("Self","Other"))

# Clear data for all following analysis

# Exclude Subject, criterion 1: procedure failure
excldSub1 <- c("7","8","2027","7035")
df.M <- df.M[!(df.M$Subject %in% excldSub1),]
df.C <- df.C[!(df.C$Subject %in% excldSub1),]

# exclude trials, criterio 1: no importance-based trials
df.C <- df.C[df.C$Task != 'importance',]  # exclude the results from importance task, should be 17856 rows

# exclude trials, criterio 2: practicing trials in matching task (first 48 trials)
subNo <- unique(df.M$Subject)
for (subj in subNo) {
        if (exists('df.M.fm')){
                df.tmp <- df.M[df.M$Subject == subj,]
                df.tmp <- df.tmp[49:nrow(df.tmp),]
                df.M.fm <- rbind(df.M.fm,df.tmp)
        } else {
                df.M.fm <- df.M[df.M$Subject == subj,]
                df.M.fm <- df.M.fm[49:nrow(df.M.fm),]
        }
}   # df.M.fm should be 14880 rows
df.M <- df.M.fm  # all the experimental trials
rm(subNo,df.M.fm,df.tmp)

# exlude subject criterion 2: less than 50% overall accuracy
# change no response to error
df.M.tmp <- df.M
df.M.tmp$ACC[df.M.tmp$ACC == -1] <- 0
df.C.tmp <- df.C
df.C.tmp$ACC[df.C.tmp$ACC == -1] <- 0 # this was not done in previous analysis, resulting the wronly excluded participants in registration

# calculate the overall accuracy for matching task
df.M.acc.g <-  ddply(df.M.tmp,.(Subject), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

# calculate the overall accuracy for categorziation task
df.C.acc.g <-  ddply(df.C.tmp,.(Subject), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

excldSub2.M <- df.M.acc.g$Subject[df.M.acc.g$ACC < 0.5]      # < 50% accuracy in matching task
excldSub2.C <- df.C.acc.g$Subject[df.C.acc.g$ACC < 0.5]      # < 50% accuracy in categorization task
df.M.valid <- df.M[!(df.M$Subject %in% excldSub2.M),]        # exclude the invalid subjects
df.C.valid <- df.C[!(df.C$Subject %in% excldSub2.M),]
df.C.valid <- df.C.valid[!(df.C.valid$Subject %in% excldSub2.C),]
rm(df.M,df.C,df.M.tmp,df.C.tmp)
```

```{r clean the data,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
# clean data for traditional analysis
df.M1 <- df.M.valid
df.C1 <- df.C.valid
df.M1$RT <- df.M1$RT * 1000 # transfer from seconds to min seconds
df.C1$RT <- df.C1$RT * 1000 # careful about the scale of time when using HDDM or ex-Gaussian

# no response equal to wrong
df.M1$ACC[df.M1$ACC == -1] <- 0
df.C1$ACC[df.C1$ACC == -1] <- 0

# excld.trials, criterion 2: correct response within 200 ms
excld.trials.M <- df.M1[df.M1$RT <= 200,]
df.M1.V        <- df.M1[!(df.M1$RT <= 200),]  # valid trial data for match task
excld.trials.C <- df.C1[df.C1$RT <= 200,]
df.C1.V        <- df.C1[!(df.C1$RT <= 200),]  # valid trial data for categorization task
nrow(excld.trials.C) + nrow(df.C1.V) == nrow(df.C1) # if true, everything is ok

## Basic information of the data ####
df.M1.T.basic <- df.M1[!duplicated(df.M1$Subject), 1:4]
numT.subj <- nrow(df.M1.T.basic)
numT.female <- sum(df.M1.T.basic$Gender == 'female');
numT.male <- sum(df.M1.T.basic$Gender == 'male');
ageT.mean <- round(mean(df.M1.T.basic$Age),2);
ageT.std <- round(sd(df.M1.T.basic$Age),2);
num.excldSub2.M <- length(unique(excldSub2.M))
num.excldSub2.C <- length(unique(excldSub2.C))

# valide data for matching task
df.M1.V.basic <- df.M1.V[!duplicated(df.M1.V$Subject), 1:4]
numV.female <- sum(df.M1.V.basic$Gender == 'female');
numV.male <- sum(df.M1.V.basic$Gender == 'male');
ageV.mean <- round(mean(df.M1.V.basic$Age),2);
ageV.std <- round(sd(df.M1.V.basic$Age),2);
ratio.excld.trials.M <- nrow(excld.trials.M)/nrow(df.M1)

# valid data for categorization task
df.C1.V.basic <- df.C1.V[!duplicated(df.C1.V$Subject), 1:4]
numV.female.C <- sum(df.C1.V.basic$Gender == 'female');
numV.male.C <- sum(df.C1.V.basic$Gender == 'male');
ageV.mean.C <- round(mean(df.C1.V.basic$Age),2);
ageV.std.C <- round(sd(df.C1.V.basic$Age),2);
ratio.excld.trials.C <- nrow(excld.trials.C)/nrow(df.C1)

rm(df.M1,df.C1) # remove the no longer used varibles.

# get the data file for hddm analysis ####
df.M.ddm.v <- df.M.valid   # exclude the invalid subjects
df.C.ddm.v <- df.C.valid

# exclusion trials, criterion: trials without response or wrong key
# Note: we didn't remove the correct response less than 200 ms
df.M.hddm <- subset(df.M.ddm.v, ACC ==1 | ACC == 0)  
df.C.hddm <- subset(df.C.ddm.v, ACC ==1 | ACC == 0) 

df.M.hddm_m <- subset(df.M.hddm, Match == 'match') # select data
df.M.hddm_m <- df.M.hddm_m[,c('Subject','Morality','Identity','RT','ACC')] # select column
colnames(df.M.hddm_m) <- c("subj_idx","val",'id','rt','response')     # change column name

df.M.hddm_nm <- subset(df.M.hddm, Match == 'nonmatch')
df.M.hddm_nm <- df.M.hddm_nm[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.M.hddm_nm) <- c("subj_idx","val",'id','rt','response')

df.C.hddm_val <- subset(df.C.hddm, Task == 'Val')
df.C.hddm_val <- df.C.hddm_val[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.C.hddm_val) <- c("subj_idx","val",'id','rt','response')

df.C.hddm_id <- subset(df.C.hddm, Task == 'Id')
df.C.hddm_id <- df.C.hddm_id[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.C.hddm_id) <- c("subj_idx","val",'id','rt','response')

setwd(ddmDir)
write.csv(df.M.hddm_m,'MS_match_hddm.csv',row.names = F)
write.csv(df.M.hddm_nm,'MS_mismatch_hddm.csv',row.names = F)
write.csv(df.C.hddm_val,'MS_categ_val_hddm.csv',row.names = F)
write.csv(df.C.hddm_id,'MS_categ_id_hddm.csv',row.names = F)
setwd(curDir)
rm('df.M.hddm','df.C.hddm','df.M.hddm_m','df.M.hddm_nm','df.C.hddm_val','df.C.hddm_id')

# get the data for exGaussian analysis
df.C.exG <- df.C.valid
df.C.exG <- subset(df.C.exG, ACC == 1 & RT > .2)
setwd(exgDir)
write.csv(df.C.exG,'MS_categ_exG.csv',row.names = F)
rm(df.C.exG)

```
## Participants
`r length(subTotl)` college students (`r numT.female` female, age: `r ageT.mean` $\pm$ `r ageT.std`) participated in this experiment. All partcipants were right handed, and all had normal or corrected-to-normal vision. Informed consent was obtained from all partcipants prior to the experiment according to procedure approved by a local ethics committee. Data of `r length(excldSub1)` participants were excluded from matching task because of the procedura failure, and `r length(excldSub2.M)` of the participants data were excluded from the analysis for matching task and categorization task because of less than 50% overall accuracy for the matching task, leaving `r nrow(df.M1.V.basic)` participants (`r numV.female` female, age: `r ageV.mean` $\pm$ `r ageV.std` years) for matching task. `r length(excldSub2.C)` addtional participants's data in categorization task were excluded becasue of less than 50% accuracy for the categorization task,leaving `r nrow(df.C1.V.basic)` participants (`r numV.female.C` female, age: `r ageV.mean.C` $\pm$ `r ageV.std.C` years) for categorization task.


##Results 
For the learning phase, we excluded the first 24 trials, which is suppose to be the duration participants were practicing. Also, trials that responsed less than 200 ms or no-response was excluded.For the learning phase, `r round(ratio.excld.trials.M,4)` of the total trials was excluded, for the testing phase, `r round(ratio.excld.trials.C,4)` of the total trials was excluded.

#### Analaysis of d prime
```{r analyzing for match task, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
### ACC ####
df.M1.V.acc  <-  plyr::ddply(df.M1.V,.(Subject, Match, Morality, Identity), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

df.M1.V.acc_w <- dcast(df.M1.V.acc, Subject ~ Match + Morality + Identity,value.var = "ACC")

# rename the column number
colnames(df.M1.V.acc_w)[2:9] <- paste("ACC", colnames(df.M1.V.acc_w[,2:9]), sep = "_")

## calculate the d prime for each condition
# calculate the number of hit,CR,miss or FA 
df.M1.V$sdt <- NA
for (i in 1:nrow(df.M1.V)){
        if (df.M1.V$ACC[i] == 1 & df.M1.V$Match[i] == "match"){
                df.M1.V$sdt[i] <- "hit"
        } else if (df.M1.V$ACC[i] == 1 & df.M1.V$Match[i] == "nonmatch" ){
                df.M1.V$sdt[i] <- "CR"
        } else if (df.M1.V$ACC[i] == 0 & df.M1.V$Match[i] == "match"){
                df.M1.V$sdt[i] <- "miss"
        } else if (df.M1.V$ACC[i] == 0 & df.M1.V$Match[i] == "nonmatch" ){
                df.M1.V$sdt[i] <- "FA"
        }
}

# calculate the number of each for each condition
df.M1.V.SDT <- plyr::ddply(df.M1.V,.(Subject,Age, Gender, Morality, Identity,sdt), summarise, N = length(sdt))
df.M1.V.SDT <- df.M1.V.SDT[complete.cases(df.M1.V.SDT$sdt),] # exclude NA, which represents no-response trials

# long format to wide
df.M1.V.SDT_w <- reshape2::dcast(df.M1.V.SDT, Subject + Age + Gender + Morality + Identity ~ sdt,value.var = "N")
df.M1.V.SDT_w$miss[is.na(df.M1.V.SDT_w$miss)] <- 0 # transfer NA to 0
df.M1.V.SDT_w$FA[is.na(df.M1.V.SDT_w$FA)]     <- 0
df.M1.V.SDT_w$hitR <- df.M1.V.SDT_w$hit/(df.M1.V.SDT_w$hit + df.M1.V.SDT_w$miss)
df.M1.V.SDT_w$faR <- df.M1.V.SDT_w$FA/(df.M1.V.SDT_w$FA + df.M1.V.SDT_w$CR)

# standardized way to deal with the extreme values
for (i in 1:nrow(df.M1.V.SDT_w)){
        if (df.M1.V.SDT_w$hitR[i] == 1){
                df.M1.V.SDT_w$hitR[i] <- 1 - 1/(2*(df.M1.V.SDT_w$hit[i] + df.M1.V.SDT_w$miss[i]))
        }
}

for (i in 1:nrow(df.M1.V.SDT_w)){
        if (df.M1.V.SDT_w$faR[i] == 0){
                df.M1.V.SDT_w$faR[i] <- 1/(2*(df.M1.V.SDT_w$FA[i] + df.M1.V.SDT_w$CR[i]))
        }
}

# calculate the d prime for each condition
df.M1.V.SDT_w$dprime <- mapply(dprime,df.M1.V.SDT_w$hitR,df.M1.V.SDT_w$faR)

# transfor from long format to wide format
df.M1.V.SDT_ww <- dcast(df.M1.V.SDT_w, Subject + Age + Gender ~ Morality + Identity ,value.var = "dprime")
# rename the column number
colnames(df.M1.V.SDT_ww)[4:7] <- paste("d", colnames(df.M1.V.SDT_ww[,4:7]), sep = "_")

df.M1.V.SDT_l <- df.M1.V.SDT_w[,c(1:5,12)]

# preproc RT data ####
df.M1.V.RT <- df.M1.V[df.M1.V$ACC == 1,]

# get the summary results
df.M1.V.RT.subj <- summarySEwithin(df.M1.V.RT,measurevar = 'RT', withinvar = c('Subject','Match','Morality','Identity'),idvar = 'Subject', na.rm = TRUE)
df.M1.V.RT.subj_w <- dcast(df.M1.V.RT.subj, Subject ~ Match + Morality + Identity ,value.var = "RT") 

# rename the columns of RT data
colnames(df.M1.V.RT.subj_w)[2:9] <- paste("RT", colnames(df.M1.V.RT.subj_w[,2:9]), sep = "_")

## saving data ####
# merge the dprime and RT data and save
df.M1.V.sum_w <- merge(df.M1.V.acc_w,  df.M1.V.SDT_ww,by = "Subject")
df.M1.V.sum_w <- merge(df.M1.V.sum_w,df.M1.V.RT.subj_w,by = 'Subject')

# merge the RT and ACC data (long-format)
df.M1.V.sum_rt_acc_l <- merge(df.M1.V.acc,df.M1.V.RT.subj,by = c("Subject","Match","Morality",'Identity'))
df.M1.V.sum_rt_acc_l <- df.M1.V.sum_rt_acc_l[order(df.M1.V.sum_rt_acc_l$Subject),]

df.M1.V.sum_rt_acc_l <- df.M1.V.sum_rt_acc_l[,c("Subject","Match","Morality",'Identity',"N.x","countN","ACC","RT")]
colnames(df.M1.V.sum_rt_acc_l) <- c("Subject","Match","Morality",'Identity',"Ntrials","corrTrials","ACC","RT")

# order the columns
df.M1.V.sum_w <- df.M1.V.sum_w[,c(colnames(df.M1.V.sum_w)[c(1,10:11,2:9,12:23)])]

# calculate the effect of self-ref and valence
df.M1.v.sum_eff_w <- df.M1.V.sum_w[,1:3]
df.M1.v.sum_eff_w$d_Good_selfEffect <- df.M1.V.sum_w$d_Good_Self - df.M1.V.sum_w$d_Good_Other
df.M1.v.sum_eff_w$d_Self_valEffect   <- df.M1.V.sum_w$d_Good_Self - df.M1.V.sum_w$d_Bad_Self

df.M1.v.sum_eff_w$RT_Good_selfEffect <- df.M1.V.sum_w$RT_match_Good_Other -  df.M1.V.sum_w$RT_match_Good_Self
df.M1.v.sum_eff_w$RT_Self_valEffect   <- df.M1.V.sum_w$RT_match_Bad_Self -  df.M1.V.sum_w$RT_match_Good_Self

# write files
setwd(traDir)
write.csv(df.M1.V.sum_w,'MS_match_behav_wide.csv',row.names = F)
write.csv(df.M1.V.SDT_l,'MS_match__dprime_long.csv',row.names = F)
write.csv(df.M1.V.sum_rt_acc_l,'MS_match__rt_acc_long.csv',row.names = F)
setwd(curDir)
#ggsave("e7_L.p_rt2.pdf", e7_L.p_rt2, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")
```

```{r preproc MS_categ_task,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
df.C1.V.acc <- plyr::ddply(df.C1.V,.(Subject,Age, Gender, Task,Morality,Identity), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

# wide-format
df.C1.V.acc_w  <- dcast(df.C1.V.acc, Subject ~ Task + Morality + Identity ,value.var = "ACC")
# rename the column number
colnames(df.C1.V.acc_w)[2:9] <- paste("ACC", colnames(df.C1.V.acc_w[,2:9]), sep = "_")

# combing data from diff task for analyzing the interaction btw val and id
df.C1.V.acc_noTask  <-  plyr::ddply(df.C1.V,.(Subject, Morality, Identity), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

df.C1.V.acc_noTask_w <- dcast(df.C1.V.acc_noTask, Subject ~ Morality + Identity,value.var = "ACC")
# rename the column number
colnames(df.C1.V.acc_noTask_w)[2:5] <- paste("ACC", colnames(df.C1.V.acc_noTask_w[,2:5]), sep = "_")

# calculate the mean differences(?)
df.C1.V.acc_noTask_w$good_bad_slf <- df.C1.V.acc_noTask_w$ACC_Good_Self - df.C1.V.acc_noTask_w$ACC_Bad_Self
df.C1.V.acc_noTask_w$good_bad_oth <- df.C1.V.acc_noTask_w$ACC_Good_Self - df.C1.V.acc_noTask_w$ACC_Bad_Other
df.C1.V.acc_noTask_w$slf_oth_good <- df.C1.V.acc_noTask_w$ACC_Good_Self - df.C1.V.acc_noTask_w$ACC_Good_Other
df.C1.V.acc_noTask_w$slf_oth_bad <- df.C1.V.acc_noTask_w$ACC_Bad_Self - df.C1.V.acc_noTask_w$ACC_Bad_Other

## preprocessing RT data
df.C1.V.RT <- df.C1.V[df.C1.V$ACC == 1,]  # exclued inaccurate data
df.C1.V.RT.subj <- summarySEwithin(df.C1.V.RT,measurevar = 'RT', withinvar = c('Subject','Task','Morality','Identity'), idvar = 'Subject',na.rm = TRUE)
df.C1.V.RT.subj_w <- dcast(df.C1.V.RT.subj, Subject ~ Task + Morality + Identity ,value.var = "RT") 

# rename the columns of RT data
colnames(df.C1.V.RT.subj_w)[2:9] <- paste("RT", colnames(df.C1.V.RT.subj_w[,2:9]), sep = "_")

# combining data form different task for analyszing interaction of val and id
df.C1.V.RT.subj_noTask <- summarySEwithin(df.C1.V.RT,measurevar = 'RT', withinvar = c('Subject','Morality','Identity'), idvar = 'Subject',na.rm = TRUE)
df.C1.V.RT.subj_noTask_w <- dcast(df.C1.V.RT.subj_noTask, Subject ~ Morality + Identity ,value.var = "RT") 

# rename the columns of RT data
colnames(df.C1.V.RT.subj_noTask_w)[2:5] <- paste("RT", colnames(df.C1.V.RT.subj_noTask_w[,2:5]), sep = "_")

## saving data ####
# merge the accuracy and RT data and save
df.C1.V.sum_w <- merge(df.C1.V.acc_w,  df.C1.V.RT.subj_w,by = "Subject")
df.C1.V.sum_noTask_w <- merge(df.C1.V.acc_noTask_w,  df.C1.V.RT.subj_noTask_w,by = "Subject")

# calculate the effect of self-ref and valence
df.C1.v.sum_eff_w <- data.frame(df.C1.V.sum_w[,c('Subject')])
colnames(df.C1.v.sum_eff_w) <- 'Subject'
df.C1.v.sum_eff_w$RT_Val_Good_selfEffect <- df.C1.V.sum_w$RT_Val_Good_Other - df.C1.V.sum_w$RT_Val_Good_Self
df.C1.v.sum_eff_w$RT_Val_Self_valEffect  <- df.C1.V.sum_w$RT_Val_Bad_Self - df.C1.V.sum_w$RT_Val_Good_Self
df.C1.v.sum_eff_w$RT_Id_Good_selfEffect  <- df.C1.V.sum_w$RT_Id_Good_Other - df.C1.V.sum_w$RT_Id_Good_Self
df.C1.v.sum_eff_w$RT_Id_Self_valEffect   <- df.C1.V.sum_w$RT_Id_Bad_Self - df.C1.V.sum_w$RT_Id_Good_Self

df.C1.v.sum_eff_w$ACC_Val_Good_selfEffect <- df.C1.V.sum_w$ACC_Val_Good_Self - df.C1.V.sum_w$ACC_Val_Good_Other
df.C1.v.sum_eff_w$ACC_Val_Self_valEffect  <- df.C1.V.sum_w$ACC_Val_Good_Self - df.C1.V.sum_w$ACC_Val_Bad_Self
df.C1.v.sum_eff_w$ACC_Id_Good_selfEffect  <- df.C1.V.sum_w$ACC_Id_Good_Self - df.C1.V.sum_w$ACC_Id_Good_Other
df.C1.v.sum_eff_w$ACC_Id_Self_valEffect   <- df.C1.V.sum_w$ACC_Id_Good_Self - df.C1.V.sum_w$ACC_Id_Bad_Self

# merge the effect file
df.v.sum_eff_all_w <- merge(df.M1.v.sum_eff_w,df.C1.v.sum_eff_w,by="Subject")

# merge the RT and ACC data (long-format) ####
df.C1.V.sum_rt_acc_l <- merge(df.C1.V.acc,df.C1.V.RT.subj,by = c("Subject","Task","Morality",'Identity'))
df.C1.V.sum_rt_acc_l <- df.C1.V.sum_rt_acc_l[order(df.C1.V.sum_rt_acc_l$Subject),]

df.C1.V.sum_rt_acc_l <- df.C1.V.sum_rt_acc_l[,c("Subject","Task","Morality",'Identity',"N.x","countN","ACC","RT")]
colnames(df.C1.V.sum_rt_acc_l) <- c("Subject","Task","Morality",'Identity',"Ntrials","corrTrials","ACC","RT")

# merge the RT and ACC data without task (long-format) ####
df.C1.V.sum_rt_acc_noTask_l <- merge(df.C1.V.acc_noTask,df.C1.V.RT.subj_noTask,by = c("Subject","Morality",'Identity'))
df.C1.V.sum_rt_acc_noTask_l <- df.C1.V.sum_rt_acc_noTask_l[order(df.C1.V.sum_rt_acc_noTask_l$Subject),]

df.C1.V.sum_rt_acc_noTask_l <- df.C1.V.sum_rt_acc_noTask_l[,c("Subject","Morality",'Identity',"N.x","countN","ACC","RT")]
colnames(df.C1.V.sum_rt_acc_noTask_l) <- c("Subject","Morality",'Identity',"Ntrials","corrTrials","ACC","RT")

# write files to an upper-lelel folder
setwd(traDir)
write.csv(df.C1.V.sum_w,'MS_categ_behav_wide.csv',row.names = F)
write.csv(df.C1.V.sum_noTask_w,'MS_categ_behav_noTask_wide.csv',row.names = F)
write.csv(df.C1.V.sum_rt_acc_l,'MS_categ__rt_acc_long.csv',row.names = F)
write.csv(df.C1.V.sum_rt_acc_noTask_l,'MS_categ__rt_acc_noTask_long.csv',row.names = F)
write.csv(df.v.sum_eff_all_w,'MS_cross_taskeffect_wide.csv',row.names = F)
setwd(curDir)
```

```{r plot_match_data,echo=FALSE,warning=FALSE, message=FALSE}
#plot the rT data from matching task
MSplots(saveDir = traDir, curDir = curDir, task = 'match',type = 'RT', inData = df.M1.V.sum_rt_acc_l)

# plot the dprime data from matching task
MSplots(saveDir = traDir, curDir = curDir, task = 'match',type = 'dprime', inData = df.M1.V.SDT_l)

```

```{r plot_categ_val_data,echo=FALSE,warning=FALSE, message=FALSE}
# plot ACC
MSplots(saveDir = traDir, curDir = curDir, task = 'val',type = 'ACC', inData = df.C1.V.sum_rt_acc_l)

# plot RT
MSplots(saveDir = traDir, curDir = curDir, task = 'val',type = 'RT', inData = df.C1.V.sum_rt_acc_l)

```

```{r plot_categ_ID_data,echo=FALSE,warning=FALSE, message=FALSE}
# plot ACC
MSplots(saveDir = traDir, curDir = curDir, task = 'id',type = 'ACC', inData = df.C1.V.sum_rt_acc_l)
# plot RT
MSplots(saveDir = traDir, curDir = curDir, task = 'id',type = 'RT', inData = df.C1.V.sum_rt_acc_l)
```

```{r plot_noTask_data,echo=FALSE,warning=FALSE, message=FALSE}
# plot ACC
MSplots(saveDir = traDir, curDir = curDir, task = 'categ',type = 'ACC', inData = df.C1.V.sum_rt_acc_noTask_l)
# plot RT
MSplots(saveDir = traDir, curDir = curDir, task = 'categ',type = 'RT', inData = df.C1.V.sum_rt_acc_noTask_l)
```