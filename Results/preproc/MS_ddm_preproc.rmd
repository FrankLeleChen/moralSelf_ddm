---
title: "Data_Analysis_exp7"
author: "hcp"
date: "2017-12"
output: word_document
---
<style type="text/css">

body{ /* Normal  */
   font-family: Times     
   font-size: 12px;
}
td {  /* Table  */
   font-size: 8px;
}
h1 { /* Header 1 */
 font-size: 28px;
}
h2 { /* Header 2 */
 font-size: 22px;
}
h3 { /* Header 3 */
 font-size: 18px;
 color: DarkBlue;
}
code.r{ /* Code block */
  font-size: 10px;
}
pre { /* Code block */
  font-size: 10px
}
</style>


This script is aimed at making the analysis of the moral self experiment (DDM) reproducible. We analyzezd the data using the traditional ways (d prime/Accuracy and mean of RT)

```{r Initializing, include=FALSE}
source('Initial.r')
curDir  <- dirname(rstudioapi::getSourceEditorContext()$path)   # directory for preprocessing
rootDir <- gsub('.{7}$', '', curDir)
#rawDir <- paste(curDir,'/data/',sep = '')
traDir <- paste(rootDir,'Traditional_Analysis',sep = '')
ddmDir <- paste(rootDir,'HDDM',sep = '')
```


```{r loadingData_e7,echo=FALSE,results='hide'}
df.M <- read.csv("MS_matchTask_raw.csv",header = TRUE, sep = ',', stringsAsFactors=FALSE) # data for matching task
df.C <- read.csv("MS_categTask_raw.csv",header = TRUE, sep = ',', stringsAsFactors=FALSE)  # data for categorization task

# make the variables in a specified order
df.M$Morality <- factor(df.M$Morality, levels = c("Good","Bad"))    
df.M$Identity <- factor(df.M$Identity, levels = c("Self","Other"))  
df.M$Match    <- factor(df.M$Match,    levels = c("match","nonmatch"))

# make the variables in a specified order
df.C$Morality <- factor(df.C$Morality, levels=c("Good","Bad"))    
df.C$Identity <- factor(df.C$Identity, levels=c("Self","Other"))

# Clear data for all following analysis

# Exclude Subject, criterion 1: procedure failure
excldSub1 <- c("7","8","2027","7035")
df.M <- df.M[!(df.M$Subject %in% excldSub1),]
df.C <- df.C[!(df.C$Subject %in% excldSub1),]

# exclude trials, criterio 1: no importance-based trials
df.C <- df.C[df.C$Task != 'importance',]  # exclude the results from importance task, should be 17856 rows

# exclude trials, criterio 2: practicing trials in matching task (first 48 trials)
subNo <- unique(df.M$Subject)
for (subj in subNo) {
        if (exists('df.M.fm')){
                df.tmp <- df.M[df.M$Subject == subj,]
                df.tmp <- df.tmp[49:nrow(df.tmp),]
                df.M.fm <- rbind(df.M.fm,df.tmp)
        } else {
                df.M.fm <- df.M[df.M$Subject == subj,]
                df.M.fm <- df.M.fm[49:nrow(df.M.fm),]
        }
}   # df.M.fm should be 14880 rows
df.M <- df.M.fm  # all the experimental trials
rm(subNo,df.M.fm,df.tmp)

# exlude subject criterion 2: less than 50% overall accuracy
# change no response to error
df.M.tmp <- df.M
df.M.tmp$ACC[df.M.tmp$ACC == -1] <- 0
df.C.tmp <- df.C
df.C.tmp$ACC[df.C.tmp$ACC == -1] <- 0

# calculate the overall accuracy for matching task
df.M.acc.g <-  ddply(df.M.tmp,.(Subject), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

# calculate the overall accuracy for categorziation task
df.C.acc.g <-  ddply(df.C.tmp,.(Subject), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

excldSub2.M <- df.M.acc.g$Subject[df.M.acc.g$ACC < 0.5]      # less 50% accuracy in matching task
excldSub2.C <- df.C.acc.g$Subject[df.C.acc.g$ACC < 0.5]      # less than 50% accuracy in categorization task
df.M.valid <- df.M[!(df.M$Subject %in% excldSub2.M),]        # exclude the invalid subjects
df.C.valid <- df.C[!(df.C$Subject %in% excldSub2.C),]
df.C.valid <- df.C.valid[!(df.C.valid$Subject %in% excldSub2.C),]
rm(df.M,df.C,df.M.tmp,df.C.tmp)
```

```{r clean the data_e7,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
# clean data for traditional analysis
df.M1 <- df.M.valid
df.C1 <- df.C.valid
df.M1$RT <- df.M1$RT * 1000 # transfer from seconds to min seconds
df.C1$RT <- df.C1$RT * 1000 # careful about the scale of time when using HDDM or ex-Gaussian

# no response equal to wrong
df.M1$ACC[df.M1$ACC == -1] <- 0
df.C1$ACC[df.C1$ACC == -1] <- 0

# excld.trials, criterion 2: correct response within 200 ms
excld.trials.M <- df.M1[df.M1$RT <= 200,]
df.M1.V        <- df.M1[!(df.M1$RT <= 200),]  # valid trial data for match task
excld.trials.C <- df.C1[df.C1$RT <= 200,]
df.C1.V        <- df.C1[!(df.C1$RT <= 200),]  # valid trial data for categorization task
nrow(excld.trials.C) + nrow(df.C1.V) == nrow(df.C1) # if true, everything is ok

## Basic information of the data ####
df.M1.T.basic <- df.M1[!duplicated(df.M1$Subject), 1:4]
numT.subj <- nrow(df.M1.T.basic)
numT.female <- sum(df.M1.T.basic$Gender == 'female');
numT.male <- sum(df.M1.T.basic$Gender == 'male');
ageT.mean <- round(mean(df.M1.T.basic$Age),2);
ageT.std <- round(sd(df.M1.T.basic$Age),2);
num.excldSub2.M <- length(unique(excldSub2.M))
num.excldSub2.C <- length(unique(excldSub2.C))

# valide data for matching task
df.M1.V.basic <- df.M1.V[!duplicated(df.M1.V$Subject), 1:4]
numV.female <- sum(df.M1.V.basic$Gender == 'female');
numV.male <- sum(df.M1.V.basic$Gender == 'male');
ageV.mean <- round(mean(df.M1.V.basic$Age),2);
ageV.std <- round(sd(df.M1.V.basic$Age),2);
ratio.excld.trials.M <- nrow(excld.trials.M)/nrow(df.M1)


# valid data for categorization task
df.C1.V.basic <- df.C1.V[!duplicated(df.C1.V$Subject), 1:4]
numV.female.C <- sum(df.C1.V.basic$Gender == 'female');
numV.male.C <- sum(df.C1.V.basic$Gender == 'male');
ageV.mean.C <- round(mean(df.C1.V.basic$Age),2);
ageV.std.C <- round(sd(df.C1.V.basic$Age),2);
ratio.excld.trials.C <- nrow(excld.trials.C)/nrow(df.C1)

rm(df.M1,df.C1) # remove the no longer used varibles.

# get the data file for hddm analysis
df.M.ddm.v <- df.M.valid   # exclude the invalid subjects
df.C.ddm.v <- df.C.valid

# exclusion trials, criterion: trials without response or wrong key
# Note: we didn't remove the correct response less than 200 ms
df.M.hddm <- subset(df.M.ddm.v, ACC ==1 | ACC == 0)  
df.C.hddm <- subset(df.C.ddm.v, ACC ==1 | ACC == 0) 

df.M.hddm_m <- subset(df.M.hddm, Match == 'match') # select data
df.M.hddm_m <- df.M.hddm_m[,c('Subject','Morality','Identity','RT','ACC')] # select column
colnames(df.M.hddm_m) <- c("subj_idx","val",'id','rt','response')     # change column name

df.M.hddm_nm <- subset(df.M.hddm, Match == 'nonmatch')
df.M.hddm_nm <- df.M.hddm_nm[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.M.hddm_nm) <- c("subj_idx","val",'id','rt','response')

df.C.hddm_val <- subset(df.C.hddm, Task == 'Val')
df.C.hddm_val <- df.C.hddm_val[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.C.hddm_val) <- c("subj_idx","val",'id','rt','response')

df.C.hddm_id <- subset(df.C.hddm, Task == 'Id')
df.C.hddm_id <- df.C.hddm_id[,c('Subject','Morality','Identity','RT','ACC')]
colnames(df.C.hddm_id) <- c("subj_idx","val",'id','rt','response')

setwd(ddmDir)
write.csv(df.M.hddm_m,'MS_match_hddm.csv',row.names = F)
write.csv(df.M.hddm_nm,'MS_mismatch_hddm.csv',row.names = F)
write.csv(df.C.hddm_val,'MS_categ_val_hddm.csv',row.names = F)
write.csv(df.C.hddm_id,'MS_categ_id_hddm.csv',row.names = F)
setwd(curDir)
rm('df.M.hddm','df.C.hddm','df.M.hddm_m','df.M.hddm_nm','df.C.hddm_val','df.C.hddm_id')
```
## Participants
`r numT.subj+length(excldSub1)` college students (`r numT.female` female, age: `r ageT.mean` $\pm$ `r ageT.std`) participated in experiment 7. All partcipants were right handed, and all had normal or corrected-to-normal vision. Informed consent was obtained from all partcipants prior to the experiment according to procedure approved by a local ethics committee. Data of `r length(excldSub1)` participants were excluded from matching task because of the procedura failure, and `r num.excld.sub` of the participants data were excluded from the analysis for matching task and categorization task because of less than 50% overall accuracy for the matching task, leaving `r numT.subj - num.excld.sub` participants (`r numV.female` female, age: `r ageV.mean` $\pm$ `r ageV.std` years) for matching task. `r num.excld.sub.T` addtional participants's data in categorization task were excluded becasue of less than 50% accuracy for the categorization task,leaving `r numT.subj - num.excld.sub - num.excld.sub.T` participants (`r numV.female.T` female, age: `r ageV.mean.T` $\pm$ `r ageV.std.T` years) for categorization task.


##Results 
For the learning phase, we excluded the first 24 trials, which is suppose to be the duration participants were practicing. Also, trials that responsed less than 200 ms or no-response was excluded.For the learning phase, `r round(ratio.excld.trials.L,4)` of the total trials was excluded, for the testing phase, `r round(ratio.excld.trials.T,4)` of the total trials was excluded.

### Results of Learning phase
#### Analaysis of d prime
```{r analyzing for d prime_e7_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
## calculate the d prime for each condition
# calculate the number of hit,CR,miss or FA 
df.M1.V$sdt <- NA
for (i in 1:nrow(df.M1.V)){
        if (df.M1.V$ACC[i] == 1 & df.M1.V$Match[i] == "match" & !is.na(df.M1.V$ResponseKey[i])){
                df.M1.V$sdt[i] <- "hit"
        } else if (df.M1.V$ACC[i] == 1 & df.M1.V$Match[i] == "nonmatch" & !is.na(df.M1.V$ResponseKey[i])){
                df.M1.V$sdt[i] <- "CR"
        } else if (df.M1.V$ACC[i] == 0 & df.M1.V$Match[i] == "match" & !is.na(df.M1.V$ResponseKey[i])){
                df.M1.V$sdt[i] <- "miss"
        } else if (df.M1.V$ACC[i] == 0 & df.M1.V$Match[i] == "nonmatch" & !is.na(df.M1.V$ResponseKey[i])){
                df.M1.V$sdt[i] <- "FA"
        }
}

# calculate the number of each for each condition
df.M1.V.SDT <-  ddply(df.M1.V,.(Subject,Morality, Identity,sdt), summarise, N = length(sdt))
df.M1.V.SDT <- df.M1.V.SDT[complete.cases(df.M1.V.SDT$sdt),] # exclude NA, which represents no-response trials

# long format to wide
df.M1.V.SDT_w <- dcast(df.M1.V.SDT, Subject + Morality + Identity ~ sdt,value.var = "N")
df.M1.V.SDT_w$miss[is.na(df.M1.V.SDT_w$miss)] <- 0 # transfer NA to 0
df.M1.V.SDT_w$FA[is.na(df.M1.V.SDT_w$FA)]     <- 0
df.M1.V.SDT_w$hitR <- df.M1.V.SDT_w$hit/(df.M1.V.SDT_w$hit + df.M1.V.SDT_w$miss)
df.M1.V.SDT_w$faR <- df.M1.V.SDT_w$FA/(df.M1.V.SDT_w$FA + df.M1.V.SDT_w$CR)

# standardized way to deal with the extreme values
for (i in 1:nrow(df.M1.V.SDT_w)){
        if (df.M1.V.SDT_w$hitR[i] == 1){
                df.M1.V.SDT_w$hitR[i] <- 1 - 1/(2*(df.M1.V.SDT_w$hit[i] + df.M1.V.SDT_w$miss[i]))
        }
}

for (i in 1:nrow(df.M1.V.SDT_w)){
        if (df.M1.V.SDT_w$faR[i] == 0){
                df.M1.V.SDT_w$faR[i] <- 1/(2*(df.M1.V.SDT_w$FA[i] + df.M1.V.SDT_w$CR[i]))
        }
}

# calculate the d prime for each condition
df.M1.V.SDT_w$dprime <- mapply(dprime,df.M1.V.SDT_w$hitR,df.M1.V.SDT_w$faR)

# transfor from long format to wide format
df.M1.V.SDT_ww <- dcast(df.M1.V.SDT_w, Subject ~ Identity + Morality ,value.var = "dprime")

# anova for d prime with 2*2 design
e7_L.d_anova <- ezANOVA(df.M1.V.SDT_w,dv = dprime, wid = Subject, within=.(Morality,Identity), type=3)

df.M1.V.SDT_w$Subject <- factor(df.M1.V.SDT_w$Subject)  # make the subject "factor"

# using Bayesfactor analysis (which is not reported in the document)
e7_L.dprime_anova_bf  <- anovaBF(dprime ~ Morality*Identity + Subject, data = df.M1.V.SDT_w, whichRandom = "Subject")

# Good self vs Bad self
e7_L.d.t.good_bad_slf <- t.test(df.M1.V.SDT_ww$Self_Good,df.M1.V.SDT_ww$Self_Bad,paired = TRUE)     # t-test
df.M1.V.SDT_ww$good_bad_slf <- df.M1.V.SDT_ww$Self_Good - df.M1.V.SDT_ww$Self_Bad                   # calculate the differences
e7_L.d.t.good_bad_slf.CI <- bootES(df.M1.V.SDT_ww$good_bad_slf,R = 20000, effect.type = "cohens.d") # calculate the cI using BootES

# give new names for each key information, for later use in the markdown
e7_L.d.tvalue.good_bad_slf <- round(as.numeric(e7_L.d.t.good_bad_slf[[1]]),3)
e7_L.d.df.M1.good_bad_slf <- as.numeric(e7_L.d.t.good_bad_slf[[2]])
e7_L.d.pvalue.good_bad_slf.adj <- p.adjust(as.numeric(e7_L.d.t.good_bad_slf[[3]]),"bonferroni",4)
e7_L.d.cohens.good_bad_slf <- round(e7_L.d.t.good_bad_slf.CI[[1]],4) 
e7_L.d.CI.L.good_bad_slf <- round(e7_L.d.t.good_bad_slf.CI[[12]][1],4)
e7_L.d.CI.H.good_bad_slf <- round(e7_L.d.t.good_bad_slf.CI[[12]][2],4)

# Good other vs. Bad other
e7_L.d.t.good_bad_oth <- t.test(df.M1.V.SDT_ww$Other_Good,df.M1.V.SDT_ww$Other_Bad,paired = TRUE)
df.M1.V.SDT_ww$good_bad_oth <- df.M1.V.SDT_ww$Other_Good - df.M1.V.SDT_ww$Other_Bad
e7_L.d.t.good_bad_oth.CI <- bootES(df.M1.V.SDT_ww$good_bad_oth,R = 20000, effect.type = "cohens.d")

e7_L.d.tvalue.good_bad_oth  <- round(as.numeric(e7_L.d.t.good_bad_oth[[1]]),3)
e7_L.d.df.M1.good_bad_oth  <- as.numeric(e7_L.d.t.good_bad_oth[[2]])
e7_L.d.pvalue.good_bad_oth.adj <- p.adjust(as.numeric(e7_L.d.t.good_bad_oth[[3]]),"bonferroni",4)
e7_L.d.cohens.good_bad_oth <- round(e7_L.d.t.good_bad_oth.CI[[1]],4) 
e7_L.d.CI.L.good_bad_oth <- round(e7_L.d.t.good_bad_oth.CI[[12]][1],4)
e7_L.d.CI.H.good_bad_oth <- round(e7_L.d.t.good_bad_oth.CI[[12]][2],4)

# Good self vs Good other
e7_L.d.t.slf_oth_good <- t.test(df.M1.V.SDT_ww$Self_Good,df.M1.V.SDT_ww$Other_Good,paired = TRUE)
df.M1.V.SDT_ww$slf_oth_good <- df.M1.V.SDT_ww$Self_Good - df.M1.V.SDT_ww$Other_Good
e7_L.d.t.slf_oth_good.CI <- bootES(df.M1.V.SDT_ww$slf_oth_good,R = 20000, effect.type = "cohens.d")

e7_L.d.tvalue.slf_oth_good  <- round(as.numeric(e7_L.d.t.slf_oth_good[[1]]),3)
e7_L.d.df.M1.slf_oth_good  <- as.numeric(e7_L.d.t.slf_oth_good[[2]])
e7_L.d.pvalue.slf_oth_good.adj <- p.adjust(as.numeric(e7_L.d.t.slf_oth_good[[3]]),"bonferroni",4)
e7_L.d.cohens.slf_oth_good <- round(e7_L.d.t.slf_oth_good.CI[[1]],4) 
e7_L.d.CI.L.slf_oth_good <- round(e7_L.d.t.slf_oth_good.CI[[12]][1],4)
e7_L.d.CI.H.slf_oth_good <- round(e7_L.d.t.slf_oth_good.CI[[12]][2],4)

# Bad self vs. Bad other
e7_L.d.t.slf_oth_bad <- t.test(df.M1.V.SDT_ww$Self_Bad,df.M1.V.SDT_ww$Other_Bad,paired = TRUE)
df.M1.V.SDT_ww$slf_oth_bad <- df.M1.V.SDT_ww$Self_Bad - df.M1.V.SDT_ww$Other_Bad
e7_L.d.t.slf_oth_bad.CI <- bootES(df.M1.V.SDT_ww$slf_oth_bad,R = 20000, effect.type = "cohens.d")

e7_L.d.tvalue.slf_oth_bad  <- round(as.numeric(e7_L.d.t.slf_oth_bad[[1]]),3)
e7_L.d.df.M1.slf_oth_bad <- as.numeric(e7_L.d.t.slf_oth_bad[[2]])
e7_L.d.pvalue.slf_oth_bad.adj <- p.adjust(as.numeric(e7_L.d.t.slf_oth_bad[[3]]),"bonferroni",4)
e7_L.d.cohens.slf_oth_bad <- round(e7_L.d.t.slf_oth_bad.CI[[1]],4) 
e7_L.d.CI.L.slf_oth_bad <- round(e7_L.d.t.slf_oth_bad.CI[[12]][1],4)
e7_L.d.CI.H.slf_oth_bad <- round(e7_L.d.t.slf_oth_bad.CI[[12]][2],4)

#####save the dprime and ACC data for late used ####
colnames(df.M1.V.SDT_ww) <- paste("L_d", colnames(df.M1.V.SDT_ww), sep = "_")
write.csv(df.M1.V.SDT_ww,"data_matching_v_dprime.csv",row.names=FALSE)
df.M1.V.acc <-  ddply(df.M1.V,.(Subject,Match,Identity,Morality), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))
df.M1.V.acc_w <- dcast(df.M1.V.acc, Subject ~ Match + Identity + Morality ,value.var = "ACC")
df.M1.V.acc_w$good_bad_slf <- df.M1.V.acc_w$match_Self_Good - df.M1.V.acc_w$match_Self_Bad
df.M1.V.acc_w$good_oth <- df.M1.V.acc_w$match_Other_Good - df.M1.V.acc_w$match_Other_Bad
df.M1.V.acc_w$slf_oth_good <- df.M1.V.acc_w$match_Self_Good - df.M1.V.acc_w$match_Other_Good
df.M1.V.acc_w$slf_oth_bad <- df.M1.V.acc_w$match_Self_Bad - df.M1.V.acc_w$match_Other_Bad

colnames(df.M1.V.acc_w) <- paste("L_acc", colnames(df.M1.V.acc_w), sep = "_")
colnames(df.M1.V.acc_w)[colnames(df.M1.V.acc_w) == 'L_acc_Subject'] <- 'Subject'
write.csv(df.M1.V.acc_w,"data_matching_v_acc.csv",row.names=FALSE)
##### save data for later analysis ####

df.M1.V.SDT.sum      <- summarySE(df.M1.V.SDT_w,measurevar = 'dprime',groupvars = c('Morality','Identity'))
e7_L.d.mean.GoodSelf <- round(df.M1.V.SDT.sum$dprime[df.M1.V.SDT.sum$Morality == 'Good' & df.M1.V.SDT.sum$Identity == 'Self'],3)
e7_L.d.sd.GoodSelf   <- round(df.M1.V.SDT.sum$sd[df.M1.V.SDT.sum$Morality == 'Good' & df.M1.V.SDT.sum$Identity == 'Self'],3)
e7_L.d.mean.BadSelf  <- round(df.M1.V.SDT.sum$dprime[df.M1.V.SDT.sum$Morality == 'Bad' & df.M1.V.SDT.sum$Identity == 'Self'],3)
e7_L.d.sd.BadSelf    <- round(df.M1.V.SDT.sum$sd[df.M1.V.SDT.sum$Morality == 'Bad' & df.M1.V.SDT.sum$Identity == 'Self'],3)

e7_L.d.mean.GoodOther <- round(df.M1.V.SDT.sum$dprime[df.M1.V.SDT.sum$Morality == 'Good' & df.M1.V.SDT.sum$Identity == 'Other'],3)
e7_L.d.sd.GoodOther   <- round(df.M1.V.SDT.sum$sd[df.M1.V.SDT.sum$Morality == 'Good' & df.M1.V.SDT.sum$Identity == 'Other'],3)
e7_L.d.mean.BadOther  <- round(df.M1.V.SDT.sum$dprime[df.M1.V.SDT.sum$Morality == 'Bad' & df.M1.V.SDT.sum$Identity == 'Other'],3)
e7_L.d.sd.BadOther    <- round(df.M1.V.SDT.sum$sd[df.M1.V.SDT.sum$Morality == 'Bad' & df.M1.V.SDT.sum$Identity == 'Other'],3)

e7_L.p_dprime1 <- ggplot(data = df.M1.V.SDT.sum,aes(y = dprime, x = Identity, group = Morality,shape = Morality, fill = Morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3,width = .6) +    # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
                      #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'self-referential',y = 'd prime') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        apatheme  + 
        theme(axis.text = element_text (size = 24,color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +  # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Good   ","Bad"))+
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

e7_L.p_dprime2 <- ggplot(data = df.M1.V.SDT.sum,aes(y = dprime, x = Morality, group = Identity,shape = Identity, fill = Identity)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
                      #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'd prime') +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        apatheme + 
        theme(axis.text = element_text (size = 24,color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce between title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("self    ","other"))+
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))
# save the plot to pdf file
ggsave("e7_L.p_dprime2.pdf", e7_L.p_dprime2, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")

MSplots(saveDir = traDir, curDir = curDir, task = 'match',type = 'dprime', inData = df.M1.V.SDT_l)

```
ANOVA for *d'* with moral character and self-relatedness as within-subjects factors.

The main effect of `r e7_L.d_anova[[1]][1,1]`, *F*(`r e7_L.d_anova[[1]][1,2]`, `r e7_L.d_anova[[1]][1,3]`) = `r round(e7_L.d_anova[[1]][1,4],3)`, *p* = `r round(e7_L.d_anova[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_L.d_anova[[1]][1,7],4)`, BF10 = r e7_L.dprime_anova_bf[1]. 

The main effect of `r e7_L.d_anova[[1]][2,1]`: *F*(`r e7_L.d_anova[[1]][2,2]`, `r e7_L.d_anova[[1]][2,3]`) = `r round(e7_L.d_anova[[1]][2,4],3)`, *p* = `r round(e7_L.d_anova[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_L.d_anova[[1]][2,7],4)`,BF10 = r e7_L.dprime_anova_bf[2]

The interaction between `r e7_L.d_anova[[1]][3,1]`: *F*(`r e7_L.d_anova[[1]][3,2]`, `r e7_L.d_anova[[1]][3,3]`) = `r round(e7_L.d_anova[[1]][3,4],3)`, *p* = `r round(e7_L.d_anova[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_L.d_anova[[1]][3,7],4)`, BF21 = r e7_L.dprime_anova_bf[4]/e7_L.dprime_anova_bf[3]

Then we conducted post-hoc comparision:

Good self (`r e7_L.d.mean.GoodSelf`  $\pm$ `r e7_L.d.sd.GoodSelf`) vs Bad self (`r e7_L.d.mean.BadSelf`  $\pm$ `r e7_L.d.sd.BadSelf`): *t*(`r e7_L.d.df.M1.good_bad_slf`) = `r e7_L.d.tvalue.good_bad_slf`, *p* = 
`r e7_L.d.pvalue.good_bad_slf.adj`, *Cohen's* $d_z$ = `r e7_L.d.cohens.good_bad_slf`, 95% CI [`r e7_L.d.CI.L.good_bad_slf` `r e7_L.d.CI.H.good_bad_slf`]


Good other (`r e7_L.d.mean.GoodOther`  $\pm$ `r e7_L.d.sd.GoodOther`) vs Bad other (`r e7_L.d.mean.BadOther`  $\pm$ `r e7_L.d.sd.BadOther`): *t*(`r e7_L.d.df.M1.good_bad_oth`) = `r e7_L.d.tvalue.good_bad_oth`, *p* = 
`r e7_L.d.pvalue.good_bad_oth.adj`, *Cohen's* $d_z$ = `r e7_L.d.cohens.good_bad_oth`, 95% CI [`r e7_L.d.CI.L.good_bad_oth` `r e7_L.d.CI.H.good_bad_oth`]

Good self (`r e7_L.d.mean.GoodSelf`  $\pm$ `r e7_L.d.sd.GoodSelf`) vs. Good other (`r e7_L.d.mean.GoodOther`  $\pm$ `r e7_L.d.sd.GoodOther`): *t*(`r e7_L.d.df.M1.slf_oth_good`) = `r e7_L.d.tvalue.slf_oth_good`, *p* = `r e7_L.d.pvalue.slf_oth_good.adj`, *Cohen's* $d_z$ = `r e7_L.d.cohens.slf_oth_good`, 95% CI [`r e7_L.d.CI.L.slf_oth_good` `r e7_L.d.CI.H.slf_oth_good`]

Bad self (`r e7_L.d.mean.BadSelf` $\pm$ `r e7_L.d.sd.BadSelf`) vs. Bad other (`r e7_L.d.mean.BadOther`  $\pm$ `r e7_L.d.sd.BadOther`): *t*(`r e7_L.d.df.M1.slf_oth_bad`) = `r e7_L.d.tvalue.slf_oth_bad`, *p* = `r e7_L.d.pvalue.slf_oth_bad.adj`, *Cohen's* $d_z$ = `r e7_L.d.cohens.slf_oth_bad`, 95% CI [`r e7_L.d.CI.L.slf_oth_bad` `r e7_L.d.CI.H.slf_oth_bad`]

```{r plot1 the d prime_e7_match, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
ggplot(data = df.M1.V.SDT.sum,aes(y = dprime, x = Identity, group = Morality,shape = Morality, fill = Morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) + # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,     # width of the error bar
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'self-referential',y = 'd prime') +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        apatheme + 
        theme(axis.text = element_text (size = 24,color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce between title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Good    ","Bad")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

```

The above figure shows the d prime for each condition (way 1)

```{r plot2 the d prime_e7_L, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
ggplot(data = df.M1.V.SDT.sum,aes(y = dprime, x = Morality, group = Identity,shape = Identity, fill = Identity)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'd prime') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        apatheme + 
        theme(axis.text = element_text (size = 24,color = 'black')) +   # set the font size and color of the axis title
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("self    ","other"))+
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

```

The above figure shows the d prime for each condition (way 2)


###Analaysis of reaction times
```{r analyzing RT_e7_L,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
df.M1.V.RT <- df.M1.V[df.M1.V$ACC == 1,]

df.M1.V.RT.subj <- summarySEwithin(df.M1.V.RT,measurevar = 'RT', withinvar = c('Subject','Match','Morality','Identity'),idvar = 'Subject', na.rm = TRUE)
df.M1.V.RT.grand <- summarySE(df.M1.V.RT.subj,measurevar = 'RT', groupvar = c('Match','Morality','Identity'),na.rm = TRUE)

df.M1.V.RT_match <- df.M1.V.RT[df.M1.V.RT$Match == "match",]
df.M1.V.RT_nonmatch <- df.M1.V.RT[df.M1.V.RT$Match == "nonmatch",]
df.M1.V.RT_match.self <- df.M1.V.RT_match[df.M1.V.RT_match$Identity == 'Self',]
df.M1.V.RT_match.other <- df.M1.V.RT_match[df.M1.V.RT_match$Identity == 'Other',]

e7_L.rt_anova <- ezANOVA(df.M1.V.RT,dv = RT, wid = Subject, within = .(Match,Morality,Identity),within_full =  .(Match,Morality,Identity), type = 3)
e7_L.rt_anova.match <- ezANOVA(df.M1.V.RT_match,dv = RT, wid = Subject, within=.(Morality,Identity),within_full=.(Identity,Morality), type=3)
e7_L.rt_anova.nonmatch <- ezANOVA(df.M1.V.RT_nonmatch,dv = RT, wid = Subject, within=.(Morality,Identity),within_full=.(Identity,Morality), type=3)

## t-test 
df.M1.V.RT.subj_w <- dcast(df.M1.V.RT.subj, Subject ~ Match + Identity + Morality ,value.var = "RT") 

# Good self vs. Bad self
e7_L.rt.t.m.good_bad_slf <- t.test(df.M1.V.RT.subj_w$match_Self_Good,df.M1.V.RT.subj_w$match_Self_Bad,paired = TRUE)
df.M1.V.RT.subj_w$m.good_bad_slf <- df.M1.V.RT.subj_w$match_Self_Good - df.M1.V.RT.subj_w$match_Self_Bad
e7_L.rt.t.m.good_bad_slf.CI <- bootES(df.M1.V.RT.subj_w$m.good_bad_slf, R = 5000,effect.type = "cohens.d")

e7_L.rt.tvalue.good_bad_slf  <- round(as.numeric(e7_L.rt.t.m.good_bad_slf [[1]]),3)
e7_L.rt.df.M1.good_bad_slf  <- as.numeric(e7_L.rt.t.m.good_bad_slf [[2]])
e7_L.rt.pvalue.good_bad_slf.adj <- p.adjust(as.numeric(e7_L.rt.t.m.good_bad_slf [[3]]),"bonferroni",4)
e7_L.rt.cohens.good_bad_slf <- round(e7_L.rt.t.m.good_bad_slf.CI[[1]],4) 
e7_L.rt.CI.L.good_bad_slf <- round(e7_L.rt.t.m.good_bad_slf.CI[[12]][1],4)
e7_L.rt.CI.H.good_bad_slf <- round(e7_L.rt.t.m.good_bad_slf.CI[[12]][2],4)

# Good Other vs. Bad Other
e7_L.rt.t.m.good_bad_oth <- t.test(df.M1.V.RT.subj_w$match_Other_Good,df.M1.V.RT.subj_w$match_Other_Bad,paired = TRUE)
df.M1.V.RT.subj_w$m.good_bad_oth <- df.M1.V.RT.subj_w$match_Other_Good - df.M1.V.RT.subj_w$match_Other_Bad
e7_L.rt.t.m.good_bad_oth.CI <- bootES(df.M1.V.RT.subj_w$m.good_bad_oth, R = 5000,effect.type = "cohens.d")

e7_L.rt.tvalue.good_bad_oth  <- round(as.numeric(e7_L.rt.t.m.good_bad_oth [[1]]),3)
e7_L.rt.df.M1.good_bad_oth  <- as.numeric(e7_L.rt.t.m.good_bad_oth [[2]])
e7_L.rt.pvalue.good_bad_oth.adj <- p.adjust(as.numeric(e7_L.rt.t.m.good_bad_oth [[3]]),"bonferroni",4)
e7_L.rt.cohens.good_bad_oth <- round(e7_L.rt.t.m.good_bad_oth.CI [[1]],4) 
e7_L.rt.CI.L.good_bad_oth <- round(e7_L.rt.t.m.good_bad_oth.CI [[12]][1],4)
e7_L.rt.CI.H.good_bad_oth <- round(e7_L.rt.t.m.good_bad_oth.CI [[12]][2],4)

# good self v. good other
e7_L.rt.t.m.slf_oth_good <- t.test(df.M1.V.RT.subj_w$match_Self_Good,df.M1.V.RT.subj_w$match_Other_Good,paired = TRUE)
df.M1.V.RT.subj_w$m.slf_oth_good <- df.M1.V.RT.subj_w$match_Self_Good - df.M1.V.RT.subj_w$match_Other_Good
e7_L.rt.t.m.slf_oth_good.CI <- bootES(df.M1.V.RT.subj_w$m.slf_oth_good, R = 5000,effect.type = "cohens.d")

e7_L.rt.tvalue.slf_oth_good  <- round(as.numeric(e7_L.rt.t.m.slf_oth_good[[1]]),3)
e7_L.rt.df.M1.slf_oth_good  <- as.numeric(e7_L.rt.t.m.slf_oth_good[[2]])
e7_L.rt.pvalue.slf_oth_good.adj <- p.adjust(as.numeric(e7_L.rt.t.m.slf_oth_good[[3]]),"bonferroni",4)
e7_L.rt.cohens.slf_oth_good <- round(e7_L.rt.t.m.slf_oth_good.CI[[1]],4) 
e7_L.rt.CI.L.slf_oth_good <- round(e7_L.rt.t.m.slf_oth_good.CI[[12]][1],4)
e7_L.rt.CI.H.slf_oth_good <- round(e7_L.rt.t.m.slf_oth_good.CI[[12]][2],4)

e7_L.rt.t.m.slf_oth_bad <- t.test(df.M1.V.RT.subj_w$match_Self_Bad,df.M1.V.RT.subj_w$match_Other_Bad,paired = TRUE)
df.M1.V.RT.subj_w$m.slf_oth_bad <- df.M1.V.RT.subj_w$match_Self_Bad - df.M1.V.RT.subj_w$match_Other_Bad
e7_L.rt.t.m.slf_oth_bad.CI <- bootES(df.M1.V.RT.subj_w$m.slf_oth_bad, R = 5000,effect.type = "cohens.d")

e7_L.rt.tvalue.slf_oth_bad  <- round(as.numeric(e7_L.rt.t.m.slf_oth_bad[[1]]),3)
e7_L.rt.df.M1.slf_oth_bad  <- as.numeric(e7_L.rt.t.m.slf_oth_bad[[2]])
e7_L.rt.pvalue.slf_oth_bad.adj <- p.adjust(as.numeric(e7_L.rt.t.m.slf_oth_bad[[3]]),"bonferroni",4)
e7_L.rt.cohens.slf_oth_bad <- round(e7_L.rt.t.m.slf_oth_bad.CI[[1]],4) 
e7_L.rt.CI.L.slf_oth_bad <- round(e7_L.rt.t.m.slf_oth_bad.CI[[12]][1],4)
e7_L.rt.CI.H.slf_oth_bad <- round(e7_L.rt.t.m.slf_oth_bad.CI[[12]][2],4)

df.M1.V.RT.grand.match <- df.M1.V.RT.grand[df.M1.V.RT.grand$Match == "match",]

##### save the rt data for late used ####
colnames(df.M1.V.RT.subj_w) <- paste("L_rt", colnames(df.M1.V.RT.subj_w), sep = "_")
colnames(df.M1.V.RT.subj_w)[colnames(df.M1.V.RT.subj_w) == 'L_rt_Subject'] <- 'Subject'
write.csv(df.M1.V.RT.subj_w,"data_matching_v_RT.csv",row.names=FALSE)
#### save the rt data ####

e7_L.rt.mean.GoodSelf <- round(df.M1.V.RT.grand.match$RT[df.M1.V.RT.grand.match$Morality == 'Good' & df.M1.V.RT.grand.match$Identity == 'Self'],0)
e7_L.rt.sd.GoodSelf <- round(df.M1.V.RT.grand.match$sd[df.M1.V.RT.grand.match$Morality == 'Good' & df.M1.V.RT.grand.match$Identity == 'Self'],0)
e7_L.rt.mean.BadSelf <- round(df.M1.V.RT.grand.match$RT[df.M1.V.RT.grand.match$Morality == 'Bad' & df.M1.V.RT.grand.match$Identity == 'Self'],0)
e7_L.rt.sd.BadSelf <- round(df.M1.V.RT.grand.match$sd[df.M1.V.RT.grand.match$Morality == 'Bad' & df.M1.V.RT.grand.match$Identity == 'Self'],0)

e7_L.rt.mean.GoodOther <- round(df.M1.V.RT.grand.match$RT[df.M1.V.RT.grand.match$Morality == 'Good' & df.M1.V.RT.grand.match$Identity == 'Other'],0)
e7_L.rt.sd.GoodOther <- round(df.M1.V.RT.grand.match$sd[df.M1.V.RT.grand.match$Morality == 'Good' & df.M1.V.RT.grand.match$Identity == 'Other'],0)
e7_L.rt.mean.BadOther <- round(df.M1.V.RT.grand.match$RT[df.M1.V.RT.grand.match$Morality == 'Bad' & df.M1.V.RT.grand.match$Identity == 'Other'],0)
e7_L.rt.sd.BadOther <- round(df.M1.V.RT.grand.match$sd[df.M1.V.RT.grand.match$Morality == 'Bad' & df.M1.V.RT.grand.match$Identity == 'Other'],0)


e7_L.p_rt1 <- ggplot(data = df.M1.V.RT.grand.match, aes(x=Identity,y=RT,group=Morality,shape = Morality,fill = Morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        xlab("Self-referential") +
        ylab(" Reaction times (ms)") + 
        coord_cartesian(ylim=c(500,800)) +
        scale_y_continuous(breaks=seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        #scale_y_continuous("Reation Times (ms)") + 
        apatheme + 
        theme(axis.text    = element_text(size = 24, color = 'black')) + 
        theme(axis.title   = element_text(size = 24)) + 
        theme(plot.title   = element_text(size = 24)) +
        theme(legend.text  = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Good   ","Bad")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

e7_L.p_rt2 <- ggplot(data = df.M1.V.RT.grand.match, aes(x=Morality,y=RT,group=Identity,shape = Identity,fill = Identity)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +   # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        xlab("Moral valence") +
        ylab(" Reaction times (ms)") + 
        coord_cartesian(ylim=c(500,800))+
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        scale_y_continuous("Reation Times  (ms)",breaks = seq(500,800,50),expand = c(0, 0)) +
        apatheme + 
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +  # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("self    ","other")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

ggsave("e7_L.p_rt2.pdf", e7_L.p_rt2, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")

```

We conducted a 2 * 3 * 2 rmANOVA for RT.

The effect of `r e7_L.rt_anova[[1]][1,1]`: *F*(`r e7_L.rt_anova[[1]][1,2]`, `r e7_L.rt_anova[[1]][1,3]`) = `r round(e7_L.rt_anova[[1]][1,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][1,7],4)`

The effect of `r e7_L.rt_anova[[1]][2,1]`: *F*(`r e7_L.rt_anova[[1]][2,2]`, `r e7_L.rt_anova[[1]][2,3]`) = `r round(e7_L.rt_anova[[1]][2,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][2,7],4)`

The effect of `r e7_L.rt_anova[[1]][3,1]`: *F*(`r e7_L.rt_anova[[1]][3,2]`, `r e7_L.rt_anova[[1]][3,3]`) = `r round(e7_L.rt_anova[[1]][3,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][3,7],4)`.

The effect of `r e7_L.rt_anova[[1]][4,1]`: *F*(`r e7_L.rt_anova[[1]][4,2]`, `r e7_L.rt_anova[[1]][4,3]`) = `r round(e7_L.rt_anova[[1]][4,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][4,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][4,7],4)`.

The effect of `r e7_L.rt_anova[[1]][5,1]`: *F*(`r e7_L.rt_anova[[1]][5,2]`, `r e7_L.rt_anova[[1]][5,3]`) = `r round(e7_L.rt_anova[[1]][5,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][5,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][5,7],4)`.

The effect of `r e7_L.rt_anova[[1]][6,1]`: *F*(`r e7_L.rt_anova[[1]][6,2]`, `r e7_L.rt_anova[[1]][6,3]`) = `r round(e7_L.rt_anova[[1]][6,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][6,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][6,7],4)`.

The effect of `r e7_L.rt_anova[[1]][7,1]`: *F*(`r e7_L.rt_anova[[1]][7,2]`, `r e7_L.rt_anova[[1]][7,3]`) = `r round(e7_L.rt_anova[[1]][7,4],3)`, *p* = `r round(e7_L.rt_anova[[1]][7,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova[[1]][7,7],4)`.


We conducted a 3 * 2 rmANOVA for RT.

**For the matched trials**, 
The effect of `r e7_L.rt_anova.match[[1]][1,1]`: *F*(`r e7_L.rt_anova.match[[1]][1,2]`, `r e7_L.rt_anova.match[[1]][1,3]`) = `r round(e7_L.rt_anova.match[[1]][1,4],3)`, *p* = `r round(e7_L.rt_anova.match[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.match[[1]][1,7],4)`

The effect of `r e7_L.rt_anova.match[[1]][2,1]`: *F*(`r e7_L.rt_anova.match[[1]][2,2]`, `r e7_L.rt_anova.match[[1]][2,3]`) = `r round(e7_L.rt_anova.match[[1]][2,4],3)`, *p* = `r round(e7_L.rt_anova.match[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.match[[1]][2,7],4)`

The effect of `r e7_L.rt_anova.match[[1]][3,1]`: *F*(`r e7_L.rt_anova.match[[1]][3,2]`, `r e7_L.rt_anova.match[[1]][3,3]`) = `r round(e7_L.rt_anova.match[[1]][3,4],3)`, *p* = `r round(e7_L.rt_anova.match[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.match[[1]][3,7],4)`.

**For the nonmatched trials**, 
The effect of `r e7_L.rt_anova.nonmatch[[1]][1,1]`: *F*(`r e7_L.rt_anova.nonmatch[[1]][1,2]`, `r e7_L.rt_anova.nonmatch[[1]][1,3]`) = `r round(e7_L.rt_anova.nonmatch[[1]][1,4],3)`, *p* = `r round(e7_L.rt_anova.nonmatch[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.nonmatch[[1]][1,7],4)`

The effect of `r e7_L.rt_anova.nonmatch[[1]][2,1]`: *F*(`r e7_L.rt_anova.nonmatch[[1]][2,2]`, `r e7_L.rt_anova.nonmatch[[1]][2,3]`) = `r round(e7_L.rt_anova.nonmatch[[1]][2,4],3)`, *p* = `r round(e7_L.rt_anova.nonmatch[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.nonmatch[[1]][2,7],4)`

The effect of `r e7_L.rt_anova.nonmatch[[1]][3,1]`: *F*(`r e7_L.rt_anova.nonmatch[[1]][3,2]`, `r e7_L.rt_anova.nonmatch[[1]][3,3]`) = `r round(e7_L.rt_anova.nonmatch[[1]][3,4],3)`, *p* = `r round(e7_L.rt_anova.nonmatch[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_L.rt_anova.nonmatch[[1]][3,7],4)`.

We conducted post-hoc comparison

Good self (`r e7_L.rt.mean.GoodSelf` $\pm$ `r e7_L.rt.sd.GoodSelf`) vs Bad self (`r e7_L.rt.mean.BadSelf` $\pm$ `r e7_L.rt.sd.BadSelf`): *t*(`r e7_L.rt.df.M1.good_bad_slf`) = `r e7_L.rt.tvalue.good_bad_slf`, *p* = 
`r e7_L.rt.pvalue.good_bad_slf.adj`, *Cohen's* $d_z$ = `r e7_L.rt.cohens.good_bad_slf`, 95% CI [`r e7_L.rt.CI.L.good_bad_slf` `r e7_L.rt.CI.H.good_bad_slf`]

Good other (`r e7_L.rt.mean.GoodOther` $\pm$ `r e7_L.rt.sd.GoodOther`)  vs Bad other (`r e7_L.rt.mean.BadOther` $\pm$ `r e7_L.rt.sd.BadOther`): *t*(`r e7_L.rt.df.M1.good_bad_oth`) = `r e7_L.rt.tvalue.good_bad_oth`, *p* = 
`r e7_L.rt.pvalue.good_bad_oth.adj`, *Cohen's* $d_z$ = `r e7_L.rt.cohens.good_bad_oth`, 95% CI [`r e7_L.rt.CI.L.good_bad_oth` `r e7_L.rt.CI.H.good_bad_oth`]

Good self (`r e7_L.rt.mean.GoodSelf` $\pm$ `r e7_L.rt.sd.GoodSelf`) vs. Good other (`r e7_L.rt.mean.GoodOther` $\pm$ `r e7_L.rt.sd.GoodOther`) : *t*(`r e7_L.rt.df.M1.slf_oth_good`) = `r e7_L.rt.tvalue.slf_oth_good`, *p* = `r e7_L.rt.pvalue.slf_oth_good.adj`, *Cohen's* $d_z$ = `r e7_L.rt.cohens.slf_oth_good`, 95% CI [`r e7_L.rt.CI.L.slf_oth_good` `r e7_L.rt.CI.H.slf_oth_good`]

Bad self (`r e7_L.rt.mean.BadSelf` $\pm$ `r e7_L.rt.sd.BadSelf`) vs. Bad other (`r e7_L.rt.mean.BadOther` $\pm$ `r e7_L.rt.sd.BadOther`): *t*(`r e7_L.rt.df.M1.slf_oth_bad`) = `r e7_L.rt.tvalue.slf_oth_bad`, *p* = `r e7_L.rt.pvalue.slf_oth_bad.adj`, *Cohen's* $d_z$ = `r e7_L.rt.cohens.slf_oth_bad`, 95% CI [`r e7_L.rt.CI.L.slf_oth_bad` `r e7_L.rt.CI.H.slf_oth_bad`]


```{r plot2 the RT_e7_L, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
# change a way to plot
ggplot(data = df.M1.V.RT.grand.match, aes(x=Identity,y=RT,group=Morality,shape = Morality,fill = Morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        xlab("Self-referential") +
        ylab(" Reaction times (ms)") + 
        coord_cartesian(ylim=c(500,800)) +
        scale_y_continuous(breaks=seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        #scale_y_continuous("Reation Times (ms)") + 
        apatheme + 
        theme(axis.text = element_text (size = 24,color = 'black')) +   # set the font size and color of the axis title
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Good    ","Bad"))+
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

```

The above is the reaction time for each condition (way 1)

```{r plot1 the RT_e7_L, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
# df.M1.V.RT.grand.match <- df.M1.V.RT.grand[df.M1.V.RT.grand$Matchness == "match",]
ggplot(data = df.M1.V.RT.grand.match, aes(x=Morality,y=RT,group=Identity,shape = Identity,fill = Identity)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) + # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        xlab("Moral valence") +
        ylab(" Reaction times (ms)") + 
        coord_cartesian(ylim=c(500,800))+
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        scale_y_continuous("Reation Times  (ms)",expand = c(0, 0)) + 
        apatheme + 
        theme(axis.text = element_text (size = 24,color = 'black')) +   # set the font size and color of the axis title
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("self    ","other")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

```

The above is the reaction time for each condition (way 2)


### Analyzing data from testing phase
We only analyzed data for self-other categorization and Good-Bad categorization data

#### analysis of ACC
```{r clean the data_e7_T,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
# df.C1.V <- df.C1.V[df.C1.V$Task != "importance",]
df.C1.V$ACC[df.C1.V$ACC==-1] <-0

df.C1.V.acc.subj <-  ddply(df.C1.V,.(Subject,Task,Morality,Identity), summarise,
                    N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC))

# define the level of factor# make the variables in a specified order
df.C1.V.acc.subj$Morality <- factor(df.C1.V.acc.subj$Morality, levels=c("Good","Bad")) 
df.C1.V.acc.subj$Identity <- factor(df.C1.V.acc.subj$Identity, levels=c("Self","Other"))

df.C1.V.acc.subj.Self <- df.C1.V.acc.subj[df.C1.V.acc.subj$Task == "Id_task",]
df.C1.V.acc.subj.Good <- df.C1.V.acc.subj[df.C1.V.acc.subj$Task == "Valence_task",]


e7_T.acc_anova <- ezANOVA(df.C1.V.acc.subj,dv = ACC, wid = Subject, within=.(Task,Morality,Identity), type=3)
e7_T.acc_anova.self <- ezANOVA(df.C1.V.acc.subj.Self, dv = ACC, wid = Subject, within=.(Morality,Identity), type=3)
e7_T.acc_anova.Good <- ezANOVA(df.C1.V.acc.subj.Good, dv = ACC, wid = Subject, within=.(Morality,Identity), type=3)

df.C1.V.acc.sum <- summarySE(df.C1.V.acc.subj,measurevar = 'ACC',groupvars = c('Task','Morality','Identity'))

df.C1.V.acc.subj_w  <- dcast(df.C1.V.acc.subj, Subject ~ Task + Identity + Morality ,value.var = "ACC")

# calculate the mean difference for moral effect (Good-Bad)
df.C1.V.acc.subj_w$Valence_good_bad_slf <- df.C1.V.acc.subj_w$Valence_task_Self_Good - df.C1.V.acc.subj_w$Valence_task_Self_Bad
df.C1.V.acc.subj_w$Valence_good_bad_oth <- df.C1.V.acc.subj_w$Valence_task_Other_Good - df.C1.V.acc.subj_w$Valence_task_Other_Bad
df.C1.V.acc.subj_w$Id_good_bad_slf      <- df.C1.V.acc.subj_w$Id_task_Self_Good - df.C1.V.acc.subj_w$Id_task_Self_Bad
df.C1.V.acc.subj_w$ID_good_bad_oth      <- df.C1.V.acc.subj_w$Id_task_Other_Good - df.C1.V.acc.subj_w$Id_task_Other_Bad

# calculate the mean difference for self effect (self-other)
df.C1.V.acc.subj_w$Valence_slf_oth_good <- df.C1.V.acc.subj_w$Valence_task_Self_Good - df.C1.V.acc.subj_w$Valence_task_Other_Good
df.C1.V.acc.subj_w$Valence_slf_oth_bad  <- df.C1.V.acc.subj_w$Valence_task_Self_Bad - df.C1.V.acc.subj_w$Valence_task_Other_Bad
df.C1.V.acc.subj_w$Id_slf_oth_good  <- df.C1.V.acc.subj_w$Id_task_Self_Good - df.C1.V.acc.subj_w$Id_task_Other_Good
df.C1.V.acc.subj_w$Id_slf_oth_bad   <- df.C1.V.acc.subj_w$Id_task_Self_Bad - df.C1.V.acc.subj_w$Id_task_Other_Bad

colnames(df.C1.V.acc.subj_w) <- paste("T_acc", colnames(df.C1.V.acc.subj_w), sep = "_")
colnames(df.C1.V.acc.subj_w)[colnames(df.C1.V.acc.subj_w) == 'T_acc_Subject'] <- 'Subject'
write.csv(df.C1.V.acc.subj_w,"data_catigorization_v_acc.csv",row.names=FALSE)
# write.csv(df.C1.V.acc.sum,"df.C1.V.acc.sum.csv",row.names=FALSE)

# plot and save the ACC for each condition
ACC_e7_T <- ggplot(data = df.C1.V.acc.sum,aes(y = ACC, x = Morality, group = Task,shape = Task, fill = Task)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = ACC - se, ymax = ACC + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Accuracy') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("Accuracy for each condition") +
        coord_cartesian(ylim=c(0.5,1)) +
        scale_y_continuous(breaks=seq(0.5,1,0.1),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        facet_grid(.~ Identity) + 
        apatheme +
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +  # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("id criteria    ","morality criteria")) +
        theme(strip.text.x = element_text(size = 24, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

ggsave("ACC_e7_T.pdf", ACC_e7_T, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")

```
ANOVA for accuracy with task type (self-other, Good-Bad) * moral character (Good vs. Bad) and self-relatedness (self v. other) as within-subjects factors.

The main effect of `r e7_T.acc_anova[[1]][1,1]`, *F*(`r e7_T.acc_anova[[1]][1,2]`, `r e7_T.acc_anova[[1]][1,3]`) = `r round(e7_T.acc_anova[[1]][1,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][1,7],4)`. 

The main effect of `r e7_T.acc_anova[[1]][2,1]`: *F*(`r e7_T.acc_anova[[1]][2,2]`, `r e7_T.acc_anova[[1]][2,3]`) = `r round(e7_T.acc_anova[[1]][2,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][2,7],4)`

The main effect of `r e7_T.acc_anova[[1]][3,1]`: *F*(`r e7_T.acc_anova[[1]][3,2]`, `r e7_T.acc_anova[[1]][3,3]`) = `r round(e7_T.acc_anova[[1]][3,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][3,7],4)`.

The interaction between: `r e7_T.acc_anova[[1]][4,1]`: *F*(`r e7_T.acc_anova[[1]][4,2]`, `r e7_T.acc_anova[[1]][4,3]`) = `r round(e7_T.acc_anova[[1]][4,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][4,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][4,7],4)`.

The interaction between: `r e7_T.acc_anova[[1]][5,1]`: *F*(`r e7_T.acc_anova[[1]][5,2]`, `r e7_T.acc_anova[[1]][5,3]`) = `r round(e7_T.acc_anova[[1]][5,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][5,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][5,7],4)`.


The interaction between: `r e7_T.acc_anova[[1]][6,1]`: *F*(`r e7_T.acc_anova[[1]][6,2]`, `r e7_T.acc_anova[[1]][6,3]`) = `r round(e7_T.acc_anova[[1]][6,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][6,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][6,7],4)`.

The interaction between: `r e7_T.acc_anova[[1]][7,1]`: *F*(`r e7_T.acc_anova[[1]][7,2]`, `r e7_T.acc_anova[[1]][7,3]`) = `r round(e7_T.acc_anova[[1]][7,4],3)`, *p* = `r round(e7_T.acc_anova[[1]][7,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova[[1]][7,7],4)`.

Since there was no signficant interaction between Task type and other two variables, we combined the resuled from identity and valence based categorization. Given that the interaction between morality and identity was signficant, we further analyzed the simple effect.

```{r ACC_e7_T_simple_effect, ,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
# combine data cross task
# tmp <- aggregate(df.C1.V.acc.subj[,7],list(df.C1.V.acc.subj$Subject,df.C1.V.acc.subj$Morality,df.C1.V.acc.subj$Identity),mean)
df.C1.V.acc.subj.noTask <- summarySE(df.C1.V.acc.subj,measurevar = 'ACC',groupvars = c('Subject','Morality','Identity'))
df.C1.V.acc.subj.noTask_w <- dcast(df.C1.V.acc.subj.noTask, Subject ~ Identity + Morality ,value.var = "ACC")

df.C1.V.acc.subj.noTask_w$good_bad_slf <- df.C1.V.acc.subj.noTask_w$Self_Good - df.C1.V.acc.subj.noTask_w$Self_Bad
df.C1.V.acc.subj.noTask_w$good_bad_oth <- df.C1.V.acc.subj.noTask_w$Other_Good - df.C1.V.acc.subj.noTask_w$Other_Bad
df.C1.V.acc.subj.noTask_w$slf_oth_good <- df.C1.V.acc.subj.noTask_w$Self_Good - df.C1.V.acc.subj.noTask_w$Other_Good
df.C1.V.acc.subj.noTask_w$slf_oth_bad <- df.C1.V.acc.subj.noTask_w$Self_Bad - df.C1.V.acc.subj.noTask_w$Other_Bad

write.csv(df.C1.V.acc.subj.noTask_w, 'df.C1.V.acc.subj.noTask.csv',row.names = F)

e7_T.acc_anova_noTask1 <- ezANOVA(df.C1.V.acc.subj.noTask,dv = ACC, wid = Subject, within=.(Morality,Identity), type=3)
# e7_T.acc_anova_noTask1 is exactly the same as in three way rm ANOVA

# simple effect:

# Good self vs Bad self
e7_T.acc.t.good_bad_slf <- t.test(df.C1.V.acc.subj.noTask_w$Self_Good,df.C1.V.acc.subj.noTask_w$Self_Bad,paired = TRUE)
e7_T.acc.t.good_bad_slf.CI <- bootES(df.C1.V.acc.subj.noTask_w$good_bad_slf,R = 20000, effect.type = "cohens.d")

e7_T.acc.tvalue.good_bad_slf <- round(as.numeric(e7_T.acc.t.good_bad_slf[[1]]),3)
e7_T.acc.df.good_bad_slf <- as.numeric(e7_T.acc.t.good_bad_slf[[2]])
e7_T.acc.pvalue.good_bad_slf.adj <- p.adjust(as.numeric(e7_T.acc.t.good_bad_slf[[3]]),"bonferroni",4)
e7_T.acc.cohens.good_bad_slf <- round(e7_T.acc.t.good_bad_slf.CI[[1]],4) 
e7_T.acc.CI.L.good_bad_slf <- round(e7_T.acc.t.good_bad_slf.CI[[12]][1],4)
e7_T.acc.CI.H.good_bad_slf <- round(e7_T.acc.t.good_bad_slf.CI[[12]][2],4)

# Good other vs Bad other
e7_T.acc.t.good_bad_oth <- t.test(df.C1.V.acc.subj.noTask_w$Other_Good,df.C1.V.acc.subj.noTask_w$Other_Bad,paired = TRUE)
e7_T.acc.t.good_bad_oth.CI <- bootES(df.C1.V.acc.subj.noTask_w$good_bad_oth,R = 20000, effect.type = "cohens.d")

e7_T.acc.tvalue.good_bad_oth <- round(as.numeric(e7_T.acc.t.good_bad_oth[[1]]),3)
e7_T.acc.df.good_bad_oth <- as.numeric(e7_T.acc.t.good_bad_oth[[2]])
e7_T.acc.pvalue.good_bad_oth.adj <- p.adjust(as.numeric(e7_T.acc.t.good_bad_oth[[3]]),"bonferroni",4)
e7_T.acc.cohens.good_bad_oth <- round(e7_T.acc.t.good_bad_oth.CI[[1]],4) 
e7_T.acc.CI.L.good_bad_oth <- round(e7_T.acc.t.good_bad_oth.CI[[12]][1],4)
e7_T.acc.CI.H.good_bad_oth <- round(e7_T.acc.t.good_bad_oth.CI[[12]][2],4)

# Good self vs Good other
e7_T.acc.t.slf_oth_good <- t.test(df.C1.V.acc.subj.noTask_w$Self_Good,df.C1.V.acc.subj.noTask_w$Other_Good,paired = TRUE)
e7_T.acc.t.slf_oth_good.CI <- bootES(df.C1.V.acc.subj.noTask_w$slf_oth_good,R = 20000, effect.type = "cohens.d")

e7_T.acc.tvalue.slf_oth_good <- round(as.numeric(e7_T.acc.t.slf_oth_good[[1]]),3)
e7_T.acc.df.slf_oth_good <- as.numeric(e7_T.acc.t.slf_oth_good[[2]])
e7_T.acc.pvalue.slf_oth_good.adj <- p.adjust(as.numeric(e7_T.acc.t.slf_oth_good[[3]]),"bonferroni",4)
e7_T.acc.cohens.slf_oth_good <- round(e7_T.acc.t.slf_oth_good.CI[[1]],4) 
e7_T.acc.CI.L.slf_oth_good <- round(e7_T.acc.t.slf_oth_good.CI[[12]][1],4)
e7_T.acc.CI.H.slf_oth_good <- round(e7_T.acc.t.slf_oth_good.CI[[12]][2],4)

# Bad self vs Bad other
e7_T.acc.t.slf_oth_bad <- t.test(df.C1.V.acc.subj.noTask_w$Self_Bad,df.C1.V.acc.subj.noTask_w$Other_Bad,paired = TRUE)
e7_T.acc.t.slf_oth_bad.CI <- bootES(df.C1.V.acc.subj.noTask_w$slf_oth_bad,R = 20000, effect.type = "cohens.d")

e7_T.acc.tvalue.slf_oth_bad <- round(as.numeric(e7_T.acc.t.slf_oth_bad[[1]]),3)
e7_T.acc.df.slf_oth_bad <- as.numeric(e7_T.acc.t.slf_oth_bad[[2]])
e7_T.acc.pvalue.slf_oth_bad.adj <- p.adjust(as.numeric(e7_T.acc.t.slf_oth_bad[[3]]),"bonferroni",4)
e7_T.acc.cohens.slf_oth_bad <- round(e7_T.acc.t.slf_oth_bad.CI[[1]],4) 
e7_T.acc.CI.L.slf_oth_bad <- round(e7_T.acc.t.slf_oth_bad.CI[[12]][1],4)
e7_T.acc.CI.H.slf_oth_bad <- round(e7_T.acc.t.slf_oth_bad.CI[[12]][2],4)

df.C1.V.acc.sum.noTask <- summarySE(df.C1.V.acc.subj,measurevar = 'ACC',groupvars = c('Morality','Identity'))
ACC.Mean.Good.Self <- df.C1.V.acc.sum.noTask$ACC[df.C1.V.acc.sum.noTask$Identity == 'Self' & df.C1.V.acc.sum.noTask$Morality == 'Good']
ACC.SD.Good.Self <- df.C1.V.acc.sum.noTask$sd[df.C1.V.acc.sum.noTask$Identity == 'Self' & df.C1.V.acc.sum.noTask$Morality == 'Good']
ACC.Mean.Bad.Self <- df.C1.V.acc.sum.noTask$ACC[df.C1.V.acc.sum.noTask$Identity == 'Self' & df.C1.V.acc.sum.noTask$Morality == 'Bad']
ACC.SD.Bad.Self <- df.C1.V.acc.sum.noTask$sd[df.C1.V.acc.sum.noTask$Identity == 'Self' & df.C1.V.acc.sum.noTask$Morality == 'Bad']
ACC.Mean.Good.Other <- df.C1.V.acc.sum.noTask$ACC[df.C1.V.acc.sum.noTask$Identity == 'Other' & df.C1.V.acc.sum.noTask$Morality == 'Good']
ACC.SD.Good.Other <- df.C1.V.acc.sum.noTask$sd[df.C1.V.acc.sum.noTask$Identity == 'Other' & df.C1.V.acc.sum.noTask$Morality == 'Good']
ACC.Mean.Bad.Other <- df.C1.V.acc.sum.noTask$ACC[df.C1.V.acc.sum.noTask$Identity == 'Other' & df.C1.V.acc.sum.noTask$Morality == 'Bad']
ACC.SD.Bad.Other <- df.C1.V.acc.sum.noTask$sd[df.C1.V.acc.sum.noTask$Identity == 'Other' & df.C1.V.acc.sum.noTask$Morality == 'Bad']

# e7_T.acc_anova_id2 <- ezANOVA(df.C1.V.acc.subj.noTask[df.C1.V.acc.subj.noTask$Identity == 'self',],dv = ACC, wid = Subject, within=.(Morality), type=3)

# e7_T.acc_anova_id3 <- ezANOVA(df.C1.V.acc.subj[df.C1.V.acc.subj$Morality == 'Good',],dv = ACC, wid = Subject, within=.(Task,Identity), type=3)
# e7_T.acc_anova_id4 <- ezANOVA(df.C1.V.acc.subj[df.C1.V.acc.subj$Morality == 'Bad',],dv = ACC, wid = Subject, within=.(Task,Identity), type=3)

# plot the data without task variable
ACC_e7_T_noTask <- ggplot(data =df.C1.V.acc.sum.noTask,aes(y = ACC, x =Morality, group = Identity,shape = Identity, fill = Identity))+
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = ACC - se, ymax = ACC + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Accuracy') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("Accuracy for each condition") +
        coord_cartesian(ylim=c(0.5,1)) +
        scale_y_continuous(breaks=seq(0.5,1,0.1),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        #facet_grid(.~ Identity) + 
        apatheme +
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce between title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Self       ","Other")) +
        theme(strip.text.x = element_text(size = 24, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

ggsave("ACC_e7_T_noTask.pdf", ACC_e7_T_noTask, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")


```

2 by 2 ANOVA:
The main effect of `r e7_T.acc_anova_noTask1[[1]][1,1]`, *F*(`r e7_T.acc_anova_noTask1[[1]][1,2]`, `r e7_T.acc_anova_noTask1[[1]][1,3]`) = `r round(e7_T.acc_anova_noTask1[[1]][1,4],3)`, *p* = `r round(e7_T.acc_anova_noTask1[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova_noTask1[[1]][1,7],4)`. 

The main effect of `r e7_T.acc_anova_noTask1[[1]][2,1]`: *F*(`r e7_T.acc_anova_noTask1[[1]][2,2]`, `r e7_T.acc_anova_noTask1[[1]][2,3]`) = `r round(e7_T.acc_anova_noTask1[[1]][2,4],3)`, *p* = `r round(e7_T.acc_anova_noTask1[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova_noTask1[[1]][2,7],4)`

The interaction `r e7_T.acc_anova_noTask1[[1]][3,1]`: *F*(`r e7_T.acc_anova_noTask1[[1]][3,2]`, `r e7_T.acc_anova_noTask1[[1]][3,3]`) = `r round(e7_T.acc_anova_noTask1[[1]][3,4],3)`, *p* = `r round(e7_T.acc_anova_noTask1[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_T.acc_anova_noTask1[[1]][3,7],4)`.


As for the self condition, effect of moral valence was significante: t(`r e7_T.acc.df.good_bad_slf`) = `r e7_T.acc.tvalue.good_bad_slf`, p = `r e7_T.acc.pvalue.good_bad_slf.adj`, Cohen's d = `r e7_T.acc.cohens.good_bad_slf`, 95% CI[`r e7_T.acc.CI.L.good_bad_slf` `r e7_T.acc.CI.H.good_bad_slf`].
For other condition, moral valence was not significante: t(`r e7_T.acc.df.good_bad_oth`) = `r e7_T.acc.tvalue.good_bad_oth`, p = `r e7_T.acc.pvalue.good_bad_oth.adj`, Cohen's d = `r e7_T.acc.cohens.good_bad_oth`, 95% CI[`r e7_T.acc.CI.L.good_bad_oth` `r e7_T.acc.CI.H.good_bad_oth`].

The effect of identity:
for moral condition, the difference between self and other was significant:t(`r e7_T.acc.df.slf_oth_good`) = `r e7_T.acc.tvalue.slf_oth_good`, p = `r e7_T.acc.pvalue.slf_oth_good.adj`, Cohen's d = `r e7_T.acc.cohens.slf_oth_good`, 95% CI[`r e7_T.acc.CI.L.slf_oth_good` `r e7_T.acc.CI.H.slf_oth_good`].
for Bad condition, the difference between self and other was not significant:t(`r e7_T.acc.df.slf_oth_bad`) = `r e7_T.acc.tvalue.slf_oth_bad`, p = `r e7_T.acc.pvalue.slf_oth_bad.adj`, Cohen's d = `r e7_T.acc.cohens.slf_oth_bad`, 95% CI[`r e7_T.acc.CI.L.slf_oth_bad` `r e7_T.acc.CI.H.slf_oth_bad`].

Good self: `r ACC.Mean.Good.Self` + `r ACC.SD.Good.Self`
Bad self:`r ACC.Mean.Bad.Self` + `r ACC.SD.Bad.Self`
Good other: `r ACC.Mean.Good.Other` + `r ACC.SD.Good.Other`
Bad other: `r ACC.Mean.Bad.Other` + `r ACC.SD.Bad.Other`

```{r plot2 the ACC_e7_T, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
ggplot(data = df.C1.V.acc.sum,aes(y = ACC, x = Morality, group = Identity,shape = Identity, fill = Identity)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = ACC - se, ymax = ACC + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Accuracy') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("Accuracy for each condition") +
        coord_cartesian(ylim=c(0.5,1))+
        scale_y_continuous(breaks = seq(0.5,1,0.1),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        facet_grid(.~Task) + 
        apatheme  +
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce between title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Self       ","Other")) +
        theme(strip.text.x = element_text(size = 24, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))
```

The above is the ACC for each condition. left panel is the results of moral-categorization task, the right panel is the self-other categorization task.

###Analaysis of reaction times
```{r analyzing RT_e7_T,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
df.C1.V.RT <- df.C1.V[df.C1.V$ACC == 1,]
# excluded 7035 and subject8
# df.C1.V.RT <- df.C1.V.RT[!(df.C1.V.RT$Subject %in% c("8","7035")),] 
df.C1.V.RT.subj <- summarySEwithin(df.C1.V.RT,measurevar = 'RT', withinvar = c('Subject','Task','Morality','Identity'),idvar = 'Subject', na.rm = TRUE)


# define the level of factor
df.C1.V.RT.subj$Morality <- factor(df.C1.V.RT.subj$Morality, levels=c("Good","Bad")) # make the variables in a specified order
df.C1.V.RT.subj$Identity <- factor(df.C1.V.RT.subj$Identity, levels=c("Self","Other"))

df.C1.V.RT.subj_w  <- dcast(df.C1.V.RT.subj, Subject ~ Task + Identity + Morality ,value.var = "RT")

# calculate the mean difference for Good effect (Good-Bad)
df.C1.V.RT.subj_w$Valence_good_bad_slf  <- df.C1.V.RT.subj_w$Valence_task_Self_Good - df.C1.V.RT.subj_w$Valence_task_Self_Bad
df.C1.V.RT.subj_w$Valence_good_bad_oth  <- df.C1.V.RT.subj_w$Valence_task_Other_Good - df.C1.V.RT.subj_w$Valence_task_Other_Bad
df.C1.V.RT.subj_w$Id_good_bad_slf       <- df.C1.V.RT.subj_w$Id_task_Self_Good   - df.C1.V.RT.subj_w$Id_task_Self_Bad
df.C1.V.RT.subj_w$ID_good_bad_oth       <- df.C1.V.RT.subj_w$Id_task_Other_Good - df.C1.V.RT.subj_w$Id_task_Other_Bad

# calculate the mean difference for self effect (self-other)
df.C1.V.RT.subj_w$Valence_slf_oth_good <- df.C1.V.RT.subj_w$Valence_task_Self_Good   - df.C1.V.RT.subj_w$Valence_task_Other_Good
df.C1.V.RT.subj_w$valence_slf_oth_bad  <- df.C1.V.RT.subj_w$Valence_task_Self_Bad - df.C1.V.RT.subj_w$Valence_task_Other_Bad
df.C1.V.RT.subj_w$Id_slf_oth_good      <- df.C1.V.RT.subj_w$Id_task_Self_Good - df.C1.V.RT.subj_w$Id_task_Other_Good
df.C1.V.RT.subj_w$Id_slf_oth_bad       <- df.C1.V.RT.subj_w$Id_task_Self_Bad - df.C1.V.RT.subj_w$Id_task_Other_Bad

#### save the rt data for later use ####
colnames(df.C1.V.RT.subj_w) <- paste("T_rt", colnames(df.C1.V.RT.subj_w), sep = "_")
colnames(df.C1.V.RT.subj_w)[colnames(df.C1.V.RT.subj_w) == 'T_rt_Subject'] <- 'Subject'
write.csv(df.C1.V.RT.subj_w,"data_catigorization_v_rt.csv",row.names=FALSE)
###########

df.C1.V.RT.grand <- summarySE(df.C1.V.RT.subj,measurevar = 'RT', groupvar = c('Task','Morality','Identity'),na.rm = TRUE)

df.C1.V.RT_Id_task <- df.C1.V.RT[df.C1.V.RT$Task == "Id_task",]
df.C1.V.RT_Val_task <- df.C1.V.RT[df.C1.V.RT$Task == "Valence_task",]
#df.C1.V.RT_match.self <- df.C1.V.RT_match[df.C1.V.RT_match$Identity == 'self',]
#df.C1.V.RT_match.other <- df.C1.V.RT_match[df.C1.V.RT_match$Identity == 'other',]

e7_T.rt_anova <- ezANOVA(df.C1.V.RT,dv = RT, wid = Subject, within=.(Task,Morality,Identity),
                         within_full=.(Task,Identity,Morality), type=3)

e7_T.rt_anova.Id_task <- ezANOVA(df.C1.V.RT_Id_task,dv = RT, wid = Subject, 
                                 within=.(Morality,Identity),within_full=.(Identity,Morality), type=3)

e7_T.rt_anova.val_task <- ezANOVA(df.C1.V.RT_Val_task,dv = RT, wid = Subject,
                                  within=.(Morality,Identity),within_full=.(Identity,Morality), type=3)

RT_e7_T <- ggplot(data = df.C1.V.RT.grand,aes(y = RT, x = Morality, group = Task,shape = Task, fill = Task)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = RT - se, ymax = RT + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Reaction times') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("Reaction times for each condition") +
        coord_cartesian(ylim=c(500,800)) +
        scale_y_continuous(breaks=seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        facet_grid(.~ Identity) + 
        apatheme +
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +  # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("id criteria    ","morality criteria")) +
        theme(strip.text.x = element_text(size = 16, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

ggsave("RT_e7_T.pdf", RT_e7_T, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")

```

ANOVA for RT with task type (self-other, Good-Bad) * moral character (Good vs. Bad) and self-relatedness (self v. other) as within-subjects factors.

The main effect of `r e7_T.rt_anova[[1]][1,1]`, *F*(`r e7_T.rt_anova[[1]][1,2]`, `r e7_T.rt_anova[[1]][1,3]`) = `r round(e7_T.rt_anova[[1]][1,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][1,7],4)`. 

The main effect of `r e7_T.rt_anova[[1]][2,1]`: *F*(`r e7_T.rt_anova[[1]][2,2]`, `r e7_T.rt_anova[[1]][2,3]`) = `r round(e7_T.rt_anova[[1]][2,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][2,7],4)`

The main effect of `r e7_T.rt_anova[[1]][3,1]`: *F*(`r e7_T.rt_anova[[1]][3,2]`, `r e7_T.rt_anova[[1]][3,3]`) = `r round(e7_T.rt_anova[[1]][3,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][3,7],4)`.

The interaction between: `r e7_T.rt_anova[[1]][4,1]`: *F*(`r e7_T.rt_anova[[1]][4,2]`, `r e7_T.rt_anova[[1]][4,3]`) = `r round(e7_T.rt_anova[[1]][4,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][4,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][4,7],4)`.

The interaction between: `r e7_T.rt_anova[[1]][5,1]`: *F*(`r e7_T.rt_anova[[1]][5,2]`, `r e7_T.rt_anova[[1]][5,3]`) = `r round(e7_T.rt_anova[[1]][5,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][5,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][5,7],4)`.


The interaction between: `r e7_T.rt_anova[[1]][6,1]`: *F*(`r e7_T.rt_anova[[1]][6,2]`, `r e7_T.rt_anova[[1]][6,3]`) = `r round(e7_T.rt_anova[[1]][6,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][6,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][6,7],4)`.

The interaction between: `r e7_T.rt_anova[[1]][7,1]`: *F*(`r e7_T.rt_anova[[1]][7,2]`, `r e7_T.rt_anova[[1]][7,3]`) = `r round(e7_T.rt_anova[[1]][7,4],3)`, *p* = `r round(e7_T.rt_anova[[1]][7,5],4)`, $\eta_g^2$ = `r round(e7_T.rt_anova[[1]][7,7],4)`.

Since there was no signficant interaction between identity and other two variables for RT, we combined the results from different shape identity. Given that the interaction between Task and moral valence was signficant, we further analyzed the simple effect.

```{r RT_e7_T_simple_effect_noID, ,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
# combine data cross identity
df.C1.V.RT.subj.noID <- summarySE(df.C1.V.RT.subj,measurevar = 'RT',groupvars = c('Subject','Task','Morality'))
df.C1.V.RT.subj.noID_w <- dcast(df.C1.V.RT.subj.noID, Subject ~ Task + Morality ,value.var = "RT")

# valence effect under different task
df.C1.V.RT.subj.noID_w$good_bad_ID <- df.C1.V.RT.subj.noID_w$Id_task_Good - df.C1.V.RT.subj.noID_w$Id_task_Bad
df.C1.V.RT.subj.noID_w$good_bad_Val <- df.C1.V.RT.subj.noID_w$Valence_task_Good - df.C1.V.RT.subj.noID_w$Valence_task_Bad

# task effect for differnt valence
df.C1.V.RT.subj.noID_w$ID_Val_good <- df.C1.V.RT.subj.noID_w$Id_task_Good - df.C1.V.RT.subj.noID_w$Valence_task_Good
df.C1.V.RT.subj.noID_w$ID_Val_bad <- df.C1.V.RT.subj.noID_w$Id_task_Bad - df.C1.V.RT.subj.noID_w$Valence_task_Bad

write.csv(df.C1.V.RT.subj.noID_w, 'df.C1.V.RT.subj.noID_w.csv',row.names = F)

e7_T.RT_anova_noID <- ezANOVA(df.C1.V.RT.subj.noID,dv = RT, wid = Subject, within=.(Task,Morality), type=3)

# simple effect:

# Id categorization task: Good v. Bad
e7_T.RT.t.good_bad_ID <- t.test(df.C1.V.RT.subj.noID_w$Id_task_Good,df.C1.V.RT.subj.noID_w$Id_task_Bad,paired = TRUE)
e7_T.RT.t.good_bad_ID.CI <- bootES(df.C1.V.RT.subj.noID_w$good_bad_ID,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.good_bad_ID <- round(as.numeric(e7_T.RT.t.good_bad_ID[[1]]),3)
e7_T.RT.df.good_bad_ID <- as.numeric(e7_T.RT.t.good_bad_ID[[2]])
e7_T.RT.pvalue.good_bad_ID.adj <- p.adjust(as.numeric(e7_T.RT.t.good_bad_ID[[3]]),"bonferroni",4)
e7_T.RT.cohens.good_bad_ID <- round(e7_T.RT.t.good_bad_ID.CI[[1]],4) 
e7_T.RT.CI.L.good_bad_ID <- round(e7_T.RT.t.good_bad_ID.CI[[12]][1],4)
e7_T.RT.CI.H.good_bad_ID <- round(e7_T.RT.t.good_bad_ID.CI[[12]][2],4)

# moral task: Good v. Bad
e7_T.RT.t.good_bad_Val <- t.test(df.C1.V.RT.subj.noID_w$Valence_task_Good,df.C1.V.RT.subj.noID_w$Valence_task_Bad,paired = TRUE)
e7_T.RT.t.good_bad_Val.CI <- bootES(df.C1.V.RT.subj.noID_w$good_bad_Val,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.good_bad_Val <- round(as.numeric(e7_T.RT.t.good_bad_Val[[1]]),3)
e7_T.RT.df.good_bad_Val <- as.numeric(e7_T.RT.t.good_bad_Val[[2]])
e7_T.RT.pvalue.good_bad_Val.adj <- p.adjust(as.numeric(e7_T.RT.t.good_bad_Val[[3]]),"bonferroni",4)
e7_T.RT.cohens.good_bad_Val <- round(e7_T.RT.t.good_bad_Val.CI[[1]],4) 
e7_T.RT.CI.L.good_bad_Val <- round(e7_T.RT.t.good_bad_Val.CI[[12]][1],4)
e7_T.RT.CI.H.good_bad_Val <- round(e7_T.RT.t.good_bad_Val.CI[[12]][2],4)

# Good valence: self task v. moral task
e7_T.RT.t.ID_Val_good <- t.test(df.C1.V.RT.subj.noID_w$Id_task_Good,df.C1.V.RT.subj.noID_w$Valence_task_Good,paired = TRUE)
e7_T.RT.t.ID_Val_good.CI <- bootES(df.C1.V.RT.subj.noID_w$ID_Val_good,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.ID_Val_good <- round(as.numeric(e7_T.RT.t.ID_Val_good[[1]]),3)
e7_T.RT.df.ID_Val_good <- as.numeric(e7_T.RT.t.ID_Val_good[[2]])
e7_T.RT.pvalue.ID_Val_good.adj <- p.adjust(as.numeric(e7_T.RT.t.ID_Val_good[[3]]),"bonferroni",4)
e7_T.RT.cohens.ID_Val_good <- round(e7_T.RT.t.ID_Val_good.CI[[1]],4) 
e7_T.RT.CI.L.ID_Val_good <- round(e7_T.RT.t.ID_Val_good.CI[[12]][1],4)
e7_T.RT.CI.H.ID_Val_good <- round(e7_T.RT.t.ID_Val_good.CI[[12]][2],4)

# Bad valence: self task v. moral task
e7_T.RT.t.ID_Val_bad <- t.test(df.C1.V.RT.subj.noID_w$Id_task_Bad,df.C1.V.RT.subj.noID_w$Valence_task_Bad,paired = TRUE)
e7_T.RT.t.ID_Val_bad.CI <- bootES(df.C1.V.RT.subj.noID_w$ID_Val_bad,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.ID_Val_bad <- round(as.numeric(e7_T.RT.t.ID_Val_bad[[1]]),3)
e7_T.RT.df.ID_Val_bad <- as.numeric(e7_T.RT.t.ID_Val_bad[[2]])
e7_T.RT.pvalue.ID_Val_bad.adj <- p.adjust(as.numeric(e7_T.RT.t.ID_Val_bad[[3]]),"bonferroni",4)
e7_T.RT.cohens.ID_Val_bad <- round(e7_T.RT.t.ID_Val_bad.CI[[1]],4) 
e7_T.RT.CI.L.ID_Val_bad <- round(e7_T.RT.t.ID_Val_bad.CI[[12]][1],4)
e7_T.RT.CI.H.ID_Val_bad <- round(e7_T.RT.t.ID_Val_bad.CI[[12]][2],4)

RT.Mean.ID_task.Good  <- mean(df.C1.V.RT.subj.noID_w$Id_task_Good)
RT.SD.ID_task.Good  <- sd(df.C1.V.RT.subj.noID_w$Id_task_Good)
RT.Mean.ID_task.Bad <- mean(df.C1.V.RT.subj.noID_w$Id_task_Bad)
RT.SD.ID_task.Bad <- sd(df.C1.V.RT.subj.noID_w$Id_task_Bad)
RT.Mean.Val_task.Good <- mean(df.C1.V.RT.subj.noID_w$Valence_task_Good)
RT.SD.Val_task.Good <- sd(df.C1.V.RT.subj.noID_w$Valence_task_Bad)
RT.Mean.Val_task.Bad <- mean(df.C1.V.RT.subj.noID_w$Valence_task_Bad)
RT.SD.Val_task.Bad <- sd(df.C1.V.RT.subj.noID_w$Valence_task_Bad)
```
2 by 2 ANOVA:
The main effect of `r e7_T.RT_anova_noID[[1]][1,1]`, *F*(`r e7_T.RT_anova_noID[[1]][1,2]`, `r e7_T.RT_anova_noID[[1]][1,3]`) = `r round(e7_T.RT_anova_noID[[1]][1,4],3)`, *p* = `r round(e7_T.RT_anova_noID[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noID[[1]][1,7],4)`. 

The main effect of `r e7_T.RT_anova_noID[[1]][2,1]`: *F*(`r e7_T.RT_anova_noID[[1]][2,2]`, `r e7_T.RT_anova_noID[[1]][2,3]`) = `r round(e7_T.RT_anova_noID[[1]][2,4],3)`, *p* = `r round(e7_T.RT_anova_noID[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noID[[1]][2,7],4)`

The interaction `r e7_T.RT_anova_noID[[1]][3,1]`: *F*(`r e7_T.RT_anova_noID[[1]][3,2]`, `r e7_T.RT_anova_noID[[1]][3,3]`) = `r round(e7_T.RT_anova_noID[[1]][3,4],3)`, *p* = `r round(e7_T.RT_anova_noID[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noID[[1]][3,7],4)`.

As for the Identity task, effect of moral valence was significante: t(`r e7_T.RT.df.good_bad_ID`) = `r e7_T.RT.tvalue.good_bad_ID`, p = `r e7_T.RT.pvalue.good_bad_ID.adj`, Cohen's d = `r e7_T.RT.cohens.good_bad_ID`, 95% CI[`r e7_T.RT.CI.L.good_bad_ID` `r e7_T.RT.CI.H.good_bad_ID`].
For moral task : t(`r e7_T.RT.df.good_bad_Val`) = `r e7_T.RT.tvalue.good_bad_Val`, p = `r e7_T.RT.pvalue.good_bad_Val.adj`, Cohen's d = `r e7_T.RT.cohens.good_bad_Val`, 95% CI[`r e7_T.RT.CI.L.good_bad_Val` `r e7_T.RT.CI.H.good_bad_Val`].

The effect of task:
for moral condition, the difference between self and moral task:t(`r e7_T.RT.df.ID_Val_good`) = `r e7_T.RT.tvalue.ID_Val_good`, p = `r e7_T.RT.pvalue.ID_Val_good.adj`, Cohen's d = `r e7_T.RT.cohens.ID_Val_good`, 95% CI[`r e7_T.RT.CI.L.ID_Val_good` `r e7_T.RT.CI.H.ID_Val_good`].
for Bad condition, the difference between self and moral task :t(`r e7_T.RT.df.ID_Val_bad`) = `r e7_T.RT.tvalue.ID_Val_bad`, p = `r e7_T.RT.pvalue.ID_Val_bad.adj`, Cohen's d = `r e7_T.RT.cohens.ID_Val_bad`, 95% CI[`r e7_T.RT.CI.L.ID_Val_bad` `r e7_T.RT.CI.H.ID_Val_bad`].

Moral valence for self condition: `r RT.Mean.ID_task.Good ` + `r RT.SD.ID_task.Good `
Bad for self condition:`r RT.Mean.ID_task.Bad` + `r RT.SD.ID_task.Bad`
Good for moral condition: `r RT.Mean.Val_task.Good` + `r RT.SD.Val_task.Good`
Bad for moral condition: `r RT.Mean.Val_task.Bad` + `r RT.SD.Val_task.Bad`


```{r RT_e7_T_simple_effect_noTask, ,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
df.C1.V.RT.subj.noTask <- summarySE(df.C1.V.RT.subj,measurevar = 'RT',groupvars = c('Subject','Identity','Morality'))
df.C1.V.RT.subj.noTask_w <- dcast(df.C1.V.RT.subj.noTask, Subject ~ Identity + Morality ,value.var = "RT")

df.C1.V.RT.subj.noTask_w$good_bad_slf <- df.C1.V.RT.subj.noTask_w$Self_Good - df.C1.V.RT.subj.noTask_w$Self_Bad
df.C1.V.RT.subj.noTask_w$good_bad_oth <- df.C1.V.RT.subj.noTask_w$Other_Good - df.C1.V.RT.subj.noTask_w$Other_Bad
df.C1.V.RT.subj.noTask_w$slf_oth_good <- df.C1.V.RT.subj.noTask_w$Self_Good - df.C1.V.RT.subj.noTask_w$Other_Good
df.C1.V.RT.subj.noTask_w$slf_oth_bad <- df.C1.V.RT.subj.noTask_w$Self_Bad - df.C1.V.RT.subj.noTask_w$Other_Bad

write.csv(df.C1.V.RT.subj.noTask_w, 'df.C1.V.RT.subj.noTask_w.csv',row.names = F)

e7_T.RT_anova_noTask <- ezANOVA(df.C1.V.RT.subj.noTask,dv = RT, wid = Subject, within=.(Morality,Identity), type=3)
# e7_T.RT_anova_noTask1 is exactly the same as in three way rm ANOVA

# simple effect:

# Good self vs Bad self
e7_T.RT.t.good_bad_slf <- t.test(df.C1.V.RT.subj.noTask_w$Self_Good,df.C1.V.RT.subj.noTask_w$Self_Bad,paired = TRUE)
e7_T.RT.t.good_bad_slf.CI <- bootES(df.C1.V.RT.subj.noTask_w$good_bad_slf,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.good_bad_slf <- round(as.numeric(e7_T.RT.t.good_bad_slf[[1]]),3)
e7_T.RT.df.good_bad_slf <- as.numeric(e7_T.RT.t.good_bad_slf[[2]])
e7_T.RT.pvalue.good_bad_slf.adj <- p.adjust(as.numeric(e7_T.RT.t.good_bad_slf[[3]]),"bonferroni",4)
e7_T.RT.cohens.good_bad_slf <- round(e7_T.RT.t.good_bad_slf.CI[[1]],4) 
e7_T.RT.CI.L.good_bad_slf <- round(e7_T.RT.t.good_bad_slf.CI[[12]][1],4)
e7_T.RT.CI.H.good_bad_slf <- round(e7_T.RT.t.good_bad_slf.CI[[12]][2],4)

# Good other vs Bad other
e7_T.RT.t.good_bad_oth <- t.test(df.C1.V.RT.subj.noTask_w$Other_Good,df.C1.V.RT.subj.noTask_w$Other_Bad,paired = TRUE)
e7_T.RT.t.good_bad_oth.CI <- bootES(df.C1.V.RT.subj.noTask_w$good_bad_oth,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.good_bad_oth <- round(as.numeric(e7_T.RT.t.good_bad_oth[[1]]),3)
e7_T.RT.df.good_bad_oth <- as.numeric(e7_T.RT.t.good_bad_oth[[2]])
e7_T.RT.pvalue.good_bad_oth.adj <- p.adjust(as.numeric(e7_T.RT.t.good_bad_oth[[3]]),"bonferroni",4)
e7_T.RT.cohens.good_bad_oth <- round(e7_T.RT.t.good_bad_oth.CI[[1]],4) 
e7_T.RT.CI.L.good_bad_oth <- round(e7_T.RT.t.good_bad_oth.CI[[12]][1],4)
e7_T.RT.CI.H.good_bad_oth <- round(e7_T.RT.t.good_bad_oth.CI[[12]][2],4)

# Good self vs Good other
e7_T.RT.t.slf_oth_good <- t.test(df.C1.V.RT.subj.noTask_w$Self_Good,df.C1.V.RT.subj.noTask_w$Other_Good,paired = TRUE)
e7_T.RT.t.slf_oth_good.CI <- bootES(df.C1.V.RT.subj.noTask_w$slf_oth_good,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.slf_oth_good <- round(as.numeric(e7_T.RT.t.slf_oth_good[[1]]),3)
e7_T.RT.df.slf_oth_good <- as.numeric(e7_T.RT.t.slf_oth_good[[2]])
e7_T.RT.pvalue.slf_oth_good.adj <- p.adjust(as.numeric(e7_T.RT.t.slf_oth_good[[3]]),"bonferroni",4)
e7_T.RT.cohens.slf_oth_good <- round(e7_T.RT.t.slf_oth_good.CI[[1]],4) 
e7_T.RT.CI.L.slf_oth_good <- round(e7_T.RT.t.slf_oth_good.CI[[12]][1],4)
e7_T.RT.CI.H.slf_oth_good <- round(e7_T.RT.t.slf_oth_good.CI[[12]][2],4)

# Bad self vs Bad other
e7_T.RT.t.slf_oth_bad <- t.test(df.C1.V.RT.subj.noTask_w$Self_Bad,df.C1.V.RT.subj.noTask_w$Other_Bad,paired = TRUE)
e7_T.RT.t.slf_oth_bad.CI <- bootES(df.C1.V.RT.subj.noTask_w$slf_oth_bad,R = 20000, effect.type = "cohens.d")

e7_T.RT.tvalue.slf_oth_bad <- round(as.numeric(e7_T.RT.t.slf_oth_bad[[1]]),3)
e7_T.RT.df.slf_oth_bad <- as.numeric(e7_T.RT.t.slf_oth_bad[[2]])
e7_T.RT.pvalue.slf_oth_bad.adj <- p.adjust(as.numeric(e7_T.RT.t.slf_oth_bad[[3]]),"bonferroni",4)
e7_T.RT.cohens.slf_oth_bad <- round(e7_T.RT.t.slf_oth_bad.CI[[1]],4) 
e7_T.RT.CI.L.slf_oth_bad <- round(e7_T.RT.t.slf_oth_bad.CI[[12]][1],4)
e7_T.RT.CI.H.slf_oth_bad <- round(e7_T.RT.t.slf_oth_bad.CI[[12]][2],4)

RT.Mean.Good.Self <- mean(df.C1.V.RT.subj.noTask_w$Self_Good)
RT.SD.Good.Self <- sd(df.C1.V.RT.subj.noTask_w$Self_Good)
RT.Mean.Bad.Self <- mean(df.C1.V.RT.subj.noTask_w$Self_Bad)
RT.SD.Bad.Self <- sd(df.C1.V.RT.subj.noTask_w$Self_Bad)
RT.Mean.Good.Other <- mean(df.C1.V.RT.subj.noTask_w$Other_Good)
RT.SD.Good.Other <- sd(df.C1.V.RT.subj.noTask_w$Other_Good)
RT.Mean.Bad.Other <- mean(df.C1.V.RT.subj.noTask_w$Other_Bad)
RT.SD.Bad.Other <- sd(df.C1.V.RT.subj.noTask_w$Other_Bad)

df.C1.V.RT.sum.noTask <- summarySE(df.C1.V.RT.subj,measurevar = 'RT',groupvars = c('Morality','Identity'))
RT.Mean.Good.Self <- df.C1.V.RT.sum.noTask$RT[df.C1.V.RT.sum.noTask$Identity == 'self' & df.C1.V.RT.sum.noTask$Morality == 'Good']
RT.SD.Good.Self <- df.C1.V.RT.sum.noTask$sd[df.C1.V.RT.sum.noTask$Identity == 'self' & df.C1.V.RT.sum.noTask$Morality == 'Good']
RT.Mean.Bad.Self <- df.C1.V.RT.sum.noTask$RT[df.C1.V.RT.sum.noTask$Identity == 'self' & df.C1.V.RT.sum.noTask$Morality == 'Bad']
RT.SD.Bad.Self <- df.C1.V.RT.sum.noTask$sd[df.C1.V.RT.sum.noTask$Identity == 'self' & df.C1.V.RT.sum.noTask$Morality == 'Bad']
RT.Mean.Good.Other <- df.C1.V.RT.sum.noTask$RT[df.C1.V.RT.sum.noTask$Identity == 'other' & df.C1.V.RT.sum.noTask$Morality == 'Good']
RT.SD.Good.Other <- df.C1.V.RT.sum.noTask$sd[df.C1.V.RT.sum.noTask$Identity == 'other' & df.C1.V.RT.sum.noTask$Morality == 'Good']
RT.Mean.Bad.Other <- df.C1.V.RT.sum.noTask$RT[df.C1.V.RT.sum.noTask$Identity == 'other' & df.C1.V.RT.sum.noTask$Morality == 'Bad']
RT.SD.Bad.Other <- df.C1.V.RT.sum.noTask$sd[df.C1.V.RT.sum.noTask$Identity == 'other' & df.C1.V.RT.sum.noTask$Morality == 'Bad']

# plot the data without task varaible.
RT_e7_T_noTask <- ggplot(data =df.C1.V.RT.sum.noTask,aes(y = RT, x =Morality, group = Identity,shape = Identity, fill = Identity))+
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = RT - se, ymax = RT + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Reaction times') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("Reaction times for each condition") +
        coord_cartesian(ylim=c(500,800)) +
        scale_y_continuous(breaks=seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        apatheme +
        theme(axis.text = element_text (size = 24)) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +  # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce betwen title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Self       ","Other")) +
        theme(strip.text.x = element_text(size = 24, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))

ggsave("RT_e7_T_noTask.pdf", RT_e7_T_noTask, scale = 1,height = 8, width = 8, dpi = 300, family = "Times")



```
2 by 2 ANOVA:
The main effect of `r e7_T.RT_anova_noTask[[1]][1,1]`, *F*(`r e7_T.RT_anova_noTask[[1]][1,2]`, `r e7_T.RT_anova_noTask[[1]][1,3]`) = `r round(e7_T.RT_anova_noTask[[1]][1,4],3)`, *p* = `r round(e7_T.RT_anova_noTask[[1]][1,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noTask[[1]][1,7],4)`. 

The main effect of `r e7_T.RT_anova_noTask[[1]][2,1]`: *F*(`r e7_T.RT_anova_noTask[[1]][2,2]`, `r e7_T.RT_anova_noTask[[1]][2,3]`) = `r round(e7_T.RT_anova_noTask[[1]][2,4],3)`, *p* = `r round(e7_T.RT_anova_noTask[[1]][2,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noTask[[1]][2,7],4)`

The interaction `r e7_T.RT_anova_noTask[[1]][3,1]`: *F*(`r e7_T.RT_anova_noTask[[1]][3,2]`, `r e7_T.RT_anova_noTask[[1]][3,3]`) = `r round(e7_T.RT_anova_noTask[[1]][3,4],3)`, *p* = `r round(e7_T.RT_anova_noTask[[1]][3,5],4)`, $\eta_g^2$ = `r round(e7_T.RT_anova_noTask[[1]][3,7],4)`.

As for the self condition, effect of moral valence was significant: t(`r e7_T.RT.df.good_bad_slf`) = `r e7_T.RT.tvalue.good_bad_slf`, p = `r e7_T.RT.pvalue.good_bad_slf.adj`, Cohen's d = `r e7_T.RT.cohens.good_bad_slf`, 95% CI[`r e7_T.RT.CI.L.good_bad_slf` `r e7_T.RT.CI.H.good_bad_slf`].
For other condition, moral valence was not significante: t(`r e7_T.RT.df.good_bad_oth`) = `r e7_T.RT.tvalue.good_bad_oth`, p = `r e7_T.RT.pvalue.good_bad_oth.adj`, Cohen's d = `r e7_T.RT.cohens.good_bad_oth`, 95% CI[`r e7_T.RT.CI.L.good_bad_oth` `r e7_T.RT.CI.H.good_bad_oth`].

The effect of identity:
for moral condition, the difference between self and other was significant:t(`r e7_T.RT.df.slf_oth_good`) = `r e7_T.RT.tvalue.slf_oth_good`, p = `r e7_T.RT.pvalue.slf_oth_good.adj`, Cohen's d = `r e7_T.RT.cohens.slf_oth_good`, 95% CI[`r e7_T.RT.CI.L.slf_oth_good` `r e7_T.RT.CI.H.slf_oth_good`].
for Bad condition, the difference between self and other was not significant:t(`r e7_T.RT.df.slf_oth_bad`) = `r e7_T.RT.tvalue.slf_oth_bad`, p = `r e7_T.RT.pvalue.slf_oth_bad.adj`, Cohen's d = `r e7_T.RT.cohens.slf_oth_bad`, 95% CI[`r e7_T.RT.CI.L.slf_oth_bad` `r e7_T.RT.CI.H.slf_oth_bad`].

Good self: `r RT.Mean.Good.Self` + `r RT.SD.Good.Self`
Bad self:`r RT.Mean.Bad.Self` + `r RT.SD.Bad.Self`
Good other: `r RT.Mean.Good.Other` + `r RT.SD.Good.Other`
Bad other: `r RT.Mean.Bad.Other` + `r RT.SD.Bad.Other`


```{r plot2 the RT_e7_T, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
ggplot(data = df.C1.V.RT.grand,aes(y = RT, x = Morality, group = Task,shape = Task, fill = Task)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = 0.6) +  # Thinner lines
        geom_errorbar(aes(ymin = RT - se, ymax = RT + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = 1,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Reaction times') +
        ggtitle("Reaction times for each condition") +
        coord_cartesian(ylim=c(500,800)) +
        scale_y_continuous(breaks=seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        facet_grid(.~ Identity) + 
        apatheme +
        theme(axis.text = element_text (size = 24, color = 'black')) + 
        theme(axis.title = element_text (size = 24)) + 
        theme(plot.title = element_text(size = 24)) +
        theme(legend.text = element_text(size =24)) +
        theme(axis.title.y = element_text(margin=margin(0,20,0,0))) +   # increase the space between title and y axis
        theme(axis.title.x = element_text(margin=margin(20,0,0,0))) +   # increase the sapce between title and x axis
        scale_fill_manual(values=c("grey20", "grey80"),labels=c("Id_task  ","Moral_task")) +
        theme(strip.text.x = element_text(size = 24, colour = "black", angle = 0),panel.margin.x = unit(4, "lines")) +
        theme(axis.line.x = element_line(color="black", size = 1),
        axis.line.y = element_line(color="black", size = 1))
```

The above is the RT for each condition. left panel is the results of moral-categorization task, the right panel is the self-other categorization task.

####Correlation analysis: 

The correlation between ACC of match trials in match task and ACC of categorization task
```{r correlattion between learning and testing_ACC,echo=FALSE,warning=FALSE,message=FALSE }
# matching task -- d prime
#ncol(df.M1.V.SDT_ww)
# matching task -- ACC
#ncol(df.M1.V.acc_w)
# matching task -- rt
#ncol(df.M1.V.RT.subj_w)
# categorization task -- ACC
#ncol(df.C1.V.acc.subj_w)
# categorization task -- rt
#ncol(df.C1.V.RT.subj_w)

## correlation analysis for ACC
df.corr.acc <- merge(df.M1.V.acc_w[,1:5],df.C1.V.acc.subj_w[,1:9],by = 'Subject')
df.corr.acc <- df.corr.acc[,2:13]
acc.corr <- corr.test(df.corr.acc, use = "pairwise", method = "pearson",adjust = "holm")

postscript("corr_acc_original_p_05.eps", width = 2048, height = 2048)
# ,main = "acc_original"
corrplot.mixed(acc.corr[[1]],p.mat = acc.corr[[4]],sig.level = 0.05,insig = "blank")
dev.off()
corrplot.mixed(acc.corr[[1]],p.mat = acc.corr[[4]],sig.level = 0.05,insig = "blank")
```

The correlation between the self-bias and moral bias of ACC of match trials in match task and ACC of categorization task
```{r correlattion between learning and testing_ACC-bias,echo=FALSE,warning=FALSE,message=FALSE }
#df.M1.V.acc_w <- read.csv("data_matching_v_acc.csv",header = TRUE, sep = ",")
#df.C1.V.acc.subj_w <- read.csv("data_catigorization_v_acc.csv",header = TRUE,sep = ",")

df.corr.bias_acc <- merge(df.M1.V.acc_w[,c(1,10:13)],df.C1.V.acc.subj_w[,c(1,10:17)],by = 'Subject')
write.csv(df.corr.bias_acc,"df.corr.bias_acc.csv",row.names = F)
df.corr.bias_acc <- df.corr.bias_acc[,2:13]
acc_bias.corr <- corr.test(df.corr.bias_acc,use = "pairwise",method="pearson",adjust="holm", alpha=.05,ci=TRUE)
postscript("corr_acc_bias_p_05.eps", width = 2048, height = 1024)
#:main = "corr coefficient (matching-categorization) - ACC_bias"
corrplot.mixed(acc_bias.corr[[1]],p.mat = acc_bias.corr[[4]],sig.level = 0.05,insig = "blank")
dev.off()
corrplot.mixed(acc_bias.corr[[1]],p.mat = acc_bias.corr[[4]],sig.level = 0.05,insig = "blank")
```

The correlation between RT of match trials in match task and ACC of categorization task
```{r correlattion between learning and testing_RT,echo=FALSE,warning=FALSE,message=FALSE }
# correlaton analysis for rt
df.corr.rt <- merge(df.M1.V.RT.subj_w[,1:5],df.C1.V.RT.subj_w[,1:9],by = 'Subject')
df.corr.rt <- df.corr.rt[,2:13]
rt.corr <- corr.test(df.corr.rt)
postscript("corr_rt_original_p_05.eps", width = 2048, height = 2048)
# ,main = "acc_original"
corrplot.mixed(rt.corr[[1]],p.mat = rt.corr[[4]],sig.level = 0.05,insig = "blank")
dev.off()
corrplot.mixed(rt.corr[[1]],p.mat = rt.corr[[4]],sig.level = 0.05,insig = "blank")
```

The correlation between the self-bias and moral bias of RT of match trials in match task and ACC of categorization task
```{r correlattion between learning and testing_RT-bias,echo=FALSE,warning=FALSE,message=FALSE }
# merge the data by subj ID
df.corr.bias_rt <- merge(df.M1.V.RT.subj_w[,c(1,10:13)],df.C1.V.RT.subj_w[,c(1,10:17)],by = 'Subject')
write.csv(df.corr.bias_rt,"df.corr.bias_rt.csv",row.names = F)
df.corr.bias_rt <- df.corr.bias_rt[,2:13]
rt_bias.corr <- corr.test(df.corr.bias_rt)

postscript("corr_rt_bias_p_05.eps", width = 2048, height = 1024)
#:main = "corr coefficient (matching-categorization) - ACC_bias"
corrplot.mixed(rt_bias.corr[[1]],p.mat = rt_bias.corr[[4]],sig.level = 0.05,insig = "blank")
dev.off()
corrplot.mixed(rt_bias.corr[[1]],p.mat = rt_bias.corr[[4]],sig.level = 0.05,insig = "blank")
```

the effect of self on ACC
The correlation of accuracy between matching task and categrization based on morality criteria
```{r corr ACC_selfBias_between matching and categorization_val,echo=FALSE,warning=FALSE,message=FALSE }
acc.self_bias_moral <- cor.test(df.corr.bias_acc$L_acc_slf_oth_good,df.corr.bias_acc$T_acc_Valence_slf_oth_good)
df.acc.self_bias_moral <- df.corr.bias_acc[,c("L_acc_slf_oth_good","T_acc_Valence_slf_oth_good")]
colnames(df.acc.self_bias_moral) <- c("ACC_self_bias_match","ACC_self_bias_moral_categorization")
ggplot(df.acc.self_bias_moral, aes(x=ACC_self_bias_match, y=ACC_self_bias_moral_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm) +   
    ggtitle("Correlation between ACC of Matching and moral categorization (self-effect)") +
    apatheme
#ggsave("p_corr_acc_self1.eps", p_corr_acc_self1, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_acc_self1.pdf",out.type="cairo", width=8, height=6)
```

The correlation of accuracy between matching task and categrization based on identity criteria
```{r corr ACC_selfBias between matching and categorization_id,echo=FALSE,warning=FALSE,message=FALSE }
acc.self_bias_id <- cor.test(df.corr.bias_acc$L_acc_slf_oth_good,df.corr.bias_acc$T_acc_Id_slf_oth_good)
df.acc.self_bias_id <- df.corr.bias_acc[,c("L_acc_slf_oth_good","T_acc_Id_slf_oth_good")]
colnames(df.acc.self_bias_id) <- c("ACC_self_bias_match","ACC_self_bias_id_categorization")
ggplot(df.acc.self_bias_id, aes(x=ACC_self_bias_match, y=ACC_self_bias_id_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm) +   
    ggtitle("Correlation between ACC of Matching and id categorization (self-effect)") +
    apatheme
#ggsave("p_corr_acc_self2.eps", p_corr_acc_self2, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_acc_self2.pdf",out.type="cairo", width=8, height=6)
```


The effect of morality 
The correlation of accuracy between matching task and categrization based on morality criteria
```{r corr ACC_valBais between matching and categorization_val,echo=FALSE,warning=FALSE,message=FALSE }
acc.moral_bias_moral <- cor.test(df.corr.bias_acc$L_acc_good_bad_slf,df.corr.bias_acc$T_acc_Valence_good_bad_slf)
df.acc.moral_bias_moral <- df.corr.bias_acc[,c("L_acc_good_bad_slf","T_acc_Valence_good_bad_slf")]
colnames(df.acc.moral_bias_moral) <- c("ACC_moral_bias_match","ACC_moral_bias_moral_categorization")
ggplot(df.acc.moral_bias_moral, aes(x=ACC_moral_bias_match, y=ACC_moral_bias_moral_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm,fill = "gray") +   
    ggtitle("Correlation between ACC of Matching and moral categorization (moral effect)") +
    apatheme
#ggsave("p_corr_acc_moral1.eps", p_corr_acc_moral1, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_acc_moral1.pdf",out.type="cairo", width=8, height=6)
```


The correlation of accuracy between matching task and categrization based on identity criteria
```{r corr ACC_valBias between matching and categorization_id,echo=FALSE,warning=FALSE,message=FALSE }
acc.moral_bias_id <- cor.test(df.corr.bias_acc$L_acc_good_bad_slf,df.corr.bias_acc$T_acc_Id_good_bad_slf)
df.acc.moral_bias_id <- df.corr.bias_acc[,c("L_acc_good_bad_slf","T_acc_Id_good_bad_slf")]
colnames(df.acc.moral_bias_id) <- c("ACC_moral_bias_match","ACC_moral_bias_id_categorization")
ggplot(df.acc.moral_bias_id, aes(x=ACC_moral_bias_match, y=ACC_moral_bias_id_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm,fill = "gray") +   
    ggtitle("Correlation between ACC of Matching and id categorization (moral effect)") +
    apatheme
# ggsave("p_corr_acc_moral2.eps", p_corr_acc_moral2, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_acc_moral2.pdf",out.type="cairo", width=8, height=6)
```


```{r corr RT_selfBias between matching and categorization_val,echo=FALSE,warning=FALSE,message=FALSE }
rt.self_bias_moral <- cor.test(df.corr.bias_rt$L_rt_m.slf_oth_good,df.corr.bias_rt$T_rt_Valence_slf_oth_good)
df.rt.self_bias_moral <- df.corr.bias_rt[,c("L_rt_m.slf_oth_good","T_rt_Valence_slf_oth_good")]
colnames(df.rt.self_bias_moral) <- c("RT_self_bias_match","RT_self_bias_moral_categorization")
ggplot(df.rt.self_bias_moral, aes(x=RT_self_bias_match, y=RT_self_bias_moral_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm) +   
    ggtitle("Correlation between RT of Matching and moral categorization (self-effect)") +
    apatheme
#ggsave("p_corr_RT_self1.eps", p_corr_RT_self1, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_RT_self1.pdf",out.type="cairo", width=8, height=6)
```

```{r corr RT_selfBias between matching and categorization_id,echo=FALSE,warning=FALSE,message=FALSE }
rt.self_bias_id <- cor.test(df.corr.bias_rt$L_rt_m.slf_oth_good,df.corr.bias_rt$T_rt_Id_slf_oth_good)
df.rt.self_bias_id <- df.corr.bias_rt[,c("L_rt_m.slf_oth_good","T_rt_Id_slf_oth_good")]
colnames(df.rt.self_bias_id) <- c("RT_self_bias_match","RT_self_bias_id_categorization")
ggplot(df.rt.self_bias_id, aes(x=RT_self_bias_match, y=RT_self_bias_id_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm,fill = "gray") +   
    ggtitle("Correlation between RT of Matching and id categorization (self-effect)") +
    apatheme
#ggsave("p_corr_RT_self2.eps", p_corr_RT_self2, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_RT_self2.pdf",out.type="cairo", width=8, height=6)

```

```{r corr RT_valBias between matching and categorization_val,echo=FALSE,warning=FALSE,message=FALSE }
rt.moral_bias_val <- cor.test(df.corr.bias_rt$L_rt_m.good_bad_slf,df.corr.bias_rt$T_rt_Valence_good_bad_slf)
df.rt.moral_bias_moral <- df.corr.bias_rt[,c("L_rt_m.good_bad_slf","T_rt_Valence_good_bad_slf")]
colnames(df.rt.moral_bias_moral) <- c("RT_moral_bias_match","RT_moral_bias_moral_categorization")
ggplot(df.rt.moral_bias_moral, aes(x=RT_moral_bias_match, y=RT_moral_bias_moral_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm) +   
    ggtitle("Correlation between RT of Matching and moral categorization (moral-effect)") +
    apatheme
#ggsave("p_corr_RT_self1.eps", p_corr_RT_self1, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_RT_moral1.pdf",out.type="cairo", width=8, height=6)
```

```{r corr RT_valBias between matching and categorization_id,echo=FALSE,warning=FALSE,message=FALSE }
rt.moral_bias_id <- cor.test(df.corr.bias_rt$L_rt_m.good_bad_slf,df.corr.bias_rt$T_rt_Id_good_bad_slf)
df.rt.moral_bias_id <- df.corr.bias_rt[,c("L_rt_m.good_bad_slf","T_rt_Id_good_bad_slf")]
colnames(df.rt.moral_bias_id) <- c("RT_moral_bias_match","RT_moral_bias_id_categorization")
ggplot(df.rt.moral_bias_id, aes(x=RT_moral_bias_match, y=RT_moral_bias_id_categorization)) +
    geom_point() +    # Use hollow circles
    geom_smooth(method=lm) + 
    ggtitle("Correlation between RT of Matching and id categorization (moral-effect)") +
    apatheme
#ggsave("p_corr_RT_self1.eps", p_corr_RT_self1, scale = 1,height = 6, width = 8, dpi = 300, family = "Times")
dev.copy2pdf(file="p_corr_RT_moral2.pdf",out.type="cairo", width=8, height=6)
```